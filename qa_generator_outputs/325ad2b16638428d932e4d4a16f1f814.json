[
    {
        "question_answer": {
            "question": "What is Cribl Stream?",
            "answer": "Cribl Stream is a data processing platform that allows users to transform and route data in real-time.",
            "follow_up_question_1": "How does Cribl Stream work?",
            "follow_up_answer_1": "Cribl Stream uses Functions, which are pieces of JavaScript code, to process data as it passes through the platform.",
            "follow_up_question_2": "Can you give an example of a Function in Cribl Stream?",
            "follow_up_answer_2": "One example is the Mask Function, which can be used to replace sensitive data with a hash or other obfuscated value.",
            "follow_up_question_3": "What are some other core Functions in Cribl Stream?",
            "follow_up_answer_3": "Some other core Functions include Parser, Eval, and Rename, which can be used to extract, manipulate, and rename fields in the data.",
            "url": "https://docs.cribl.io/docs/getting-started-guide"
        },
        "reference": "Data tab, click Simple beside be_raw.log. This restores our preview of our original, unfiltered capture. We\u2019re ready to transform this sample data in more interesting ways, by building out our Pipeline\u2019s Functions. Functions are pieces of JavaScript code that Cribl\u00c2 Stream invokes on each event that passes through them. By\u00c2 default, this means all events \u00e2\u0080\u0093 each Function has a Filter field whose value defaults to true. As\u00c2 we just saw with data capture, you can replace this value with an expression that scopes the Function down to particular matching events. In this Pipeline, we\u2019ll use some of Cribl\u00c2 Stream\u2019s core Functions to: In the right Preview pane, notice each that event includes a social key, whose value is a (fictitious) raw Social Security number. Before this data goes any further through our Pipeline, let\u2019s use Cribl\u00c2 Stream\u2019s Mask Function to swap in an md5 hash of each SSN. In the left Pipelines pane, click Add\u00c2 Function. Search for Mask, then click it. In the new Function\u2019s Masking\u00c2 Rules, click the into Match\u00c2 Regex field. Now we want to build the Match\u00c2 Regex/Replace\u00c2 Expression row shown just below. Enter or paste this regex, which simply looks for the string social=, followed by any digits: (social=)(\\d+) In Replace\u00c2 Expression, paste the following hash function. The backticks are literal: `${g1}${C.Mask.md5(g2)}` Note that Apply to Fields defaults to _raw. This is what we want to target, so we\u2019ll accept this default. Click Save. You\u2019ll immediately notice some obvious changes: The Preview pane has switched from its IN to its OUT tab, to show you the outbound effect of the Pipeline you just saved. Each event\u2019s _raw field has changed color, to indicate that it\u2019s undergone some redactions. Now locate at least one event\u2019s Show\u00c2 more link, and click to expand it. You can verify that the social values have now been hashed. Having redacted sensitive data, we\u2019ll next use a Parser function to lift up all the _raw field\u2019s key-value pairs as fields: In the left Pipelines pane, click Add\u00c2 Function. Search for Parser, then click it. Leave the Operation\u00c2 Mode set to its Extract default. Set the Type to Key=Value Pairs. Leave the Source\u00c2 Field set to its _raw default. Click Save. You should see the Preview pane instantly light up with a lot more fields, parsed from _raw. You\u00c2 now have rich structured data, but not all of this data is particularly interesting: Note how many fields have NA (\u201cNot\u00c2 Applicable\u201d) values. We can enhance the Parser Function to ignore fields with NA values. In the Function\u2019s Fields Filter Expression field (near the bottom), enter this negation expression: value!='NA'. Note the single-quoted value. If you type (rather than paste) this expression, watch how typeahead matches the first quote you type. Click Save, and watch the Preview pane. Several fields should disappear \u00e2\u0080\u0093 such as credits, EventConversationID, and ReplyTo. The\u00c2 remaining fields should display meaningful values. Congratulations! Your log data is already starting to look better-organized and less bloated. If you didn\u2019t see the fields change, toggle the Parser Function Off, click Save below, and watch the Preview pane change. Using these toggles, you can preserve structure as you test and troubleshoot each Function\u2019s effect. Note that each Function also has a Final toggle, defaulting to Off. Enabling Final anywhere in the Functions stack will prevent data from flowing to any Functions lower in the UI. Be sure to toggle the Function back On, and click Save again, before you proceed! Next, let\u2019s add an extra field, and conditionally infer its value from existing values. We\u2019ll also remove the _raw field, now that it\u2019s redundant. To add and remove fields, the Eval Function is our pal. Let\u2019s assume we want to enrich our data by identifying the manufacturer of a certain popular phone handset. We can infer this from the existing phoneType field that we\u2019ve lifted up for each event. In the left Pipelines pane, click Add\u00c2 Function. Search for Eval, then click it. Click Add\u00c2 Field to open the Evaluate\u00c2 Fields table. Here you add new fields to events, defining each field as a key-value pair. If we needed more key-value pairs, we could click +\u00c2 Add\u00c2 Field for more rows. In the table\u2019s first row, click into the Name field and enter: phoneCompany. In the adjacent Value\u00c2 Expression field, enter this JS ternary expression that tests phoneType\u2019s value: phoneType.startsWith('iPhone') ? 'Apple' : 'Other' (Note the ? and : operators, and the single-quoted values.) Click Save. Examine some events in the Preview pane, and each should now contain a phoneCompany field that matches its phoneType. Now that we\u2019ve parsed out all of the _raw field\u2019s data \u00e2\u0080\u0093 it can go. Deleting a (large) redundant field will give us cleaner events, and reduced load on downstream resources. Still in the Eval Function, click into Remove\u00c2 Fields. Type: _raw and press Tab or Enter. Click Save. The Preview pane\u2019s diff view should now show each event\u2019s _raw field stripped out. Our log data has now been cleansed, structured, enriched, and slimmed-down. Let\u2019s next look at how to make it more legible, by giving fields simpler names. In the left Pipelines pane, click Add\u00c2 Function. This rhythm should now be familiar to you. Search for Rename, then click it. Click Add\u00c2 fields to open the Rename\u00c2 fields table. Click into the new Function\u2019s Rename\u00c2 fields table. This has the same structure you saw above in Eval: Each row defines a key-value pair. In Current\u00c2 name, enter the longhaired existing field name: conversationId. In New\u00c2 name, enter the simplified field name: ID. Watch any event\u2019s conversationId field in the Preview pane as you click Save at left. This\u00c2 field should change to ID in all events. We\u2019ve already refined our data substantially. To further slim it down, a Pipeline can entirely remove events that aren\u2019t of interest for a particular downstream service. As the \u201cPipeline\u201d name implies, your Cribl\u00c2 Stream installation can have multiple Pipelines, each configured to send out a data stream tailored to a particular Destination. This helps you get the right data in the right places most efficiently. Here, let\u2019s drop all events for customers who use prepaid monthly phone service (i.e., not postpaid): In the left Pipelines pane, click Add\u00c2 Function. Search for Drop, then click it. Click into the new Function\u2019s Filter field. Replace the default true value with this JS negation expression: accountType!='PostPaid' Click Save. Now scroll through the right Preview pane. Depending on your data sample, you should now see multiple events struck out and faded \u00e2\u0080\u0093 indicating that Cribl\u00c2 Stream will drop them before forwarding the data. Torture the data enough, and it will confess. By what factor have our transformations refined our data\u2019s volume? Let\u2019s check. In the right Preview pane, click the Basic\u00c2 Statistics button: Even without the removal of the _raw field (back in Eval) and the dropped events, you should see a substantial % reduction in the Full\u00c2 Event Length. Woo hoo! Before we wrap up our configuration: If you\u2019re curious about individual Functions\u2019 independent contribution to the data reduction shown here, you can test it now. Use the toggle\u00c2 Off\u00c2 > Save > Basic\u00c2 Statistics sequence to check various changes. We\u2019ve now built a complete, functional Pipeline. But so far, we\u2019ve tested its effects only on the static data sample we captured earlier. To get dynamic data flowing through a Pipeline, we need to filter that data in, by defining a Cribl\u00c2 Stream Route. At the Pipelines page\u2019s top left, click Attach to Route. This displays the Routes page. It\u2019s structured very similarly to the Pipelines page, so the rhythm here should feel familiar. Click Add\u00c2 Route. Enter a unique, meaningful Route Name, like demo. Leave the Filter field set to its true default, allowing it to deliver all events. Because a Route delivers events to a Pipeline, it offers a first stage of filtering. In\u00c2 production, you\u2019d typically configure each Route to filter events by appropriate source, sourcetype, index, host, _time, or other characteristics. The Filter field accepts JavaScript expressions, including AND (&&) and OR (||) operators. Set the Pipeline drop-down to our configured slicendice Pipeline. Leave the Enable Expression field set to its No default. Toggling this field to Yes changes the Output field to an Output Expression field where you can enter a JavaScript expression for your Destination name. Set the Output drop-down to either devnull or default. This doesn\u2019t matter, because we\u2019ve set default as a pointer to devnull. In\u00c2 production, you\u2019d set this carefully. You can leave the Description empty, and leave Final set to Yes. Grab the new Route by its left handle, and drag it above the default Route, so that our new Route will process events first. You should see something like the screenshot below. Click Save to save the new Route to the Routing table. If you\u2019re on Cribl.Cloud or any other distributed mode, click Commit\u00c2 &\u00c2 Deploy at Cribl\u00c2 Stream\u2019s upper right before proceeding. Then, in the resulting dialog box, click Commit\u00c2 &\u00c2 Deploy to confirm. You\u2019ll see a Commit\u00c2 successful message. The sparklines should immediately confirm that data is flowing through your new Route: To confirm data flow through the whole system we\u2019ve built, select Monitoring\u00c2 > Data > Routes and examine demo. Also select Monitoring\u00c2 > Data > Pipelines and examine slicendice. Look at you! Give yourself a pat on the back! In this short, scenic tour \u00e2\u0080\u0093 with no hit to your cloud-services charges \u00e2\u0080\u0093 you\u2019ve built a simple but complete Cribl\u00c2 Stream system, exercising all of its basic components: Interested in guided walk-throughs of more-advanced Cribl\u00c2 Stream features? We suggest that you next check out these further resources. Cribl\u00c2 Stream Sandboxes: Work through general and specific scenarios in a free, hosted environment, with terminal access and real data inputs and outputs. Distributed\u00c2 Quick\u00c2 Start: Building on this tutorial that you\u2019ve just completed, launch and configure a Cribl\u00c2 Stream distributed deployment. You\u2019ll work with a small but realistic model of a fully scaleable production deployment. Use Cases documentation: Bring your own services to build solutions to specific challenges. Cribl Concept: Pipelines \u00e2\u0080\u0093 Video showing how to build and use Pipelines at multiple Cribl\u00c2 Stream stages. Cribl Concept: Routing \u00e2\u0080\u0093 Video about using Routes to send different data through different paths. Oh yeah, you\u2019ve still got the Cribl\u00c2 Stream server running, with its businessevent.log datagen still firing events. If\u00c2 you\u2019d like to shut these down for now, in reverse order: Go to Data > Sources > Datagen. Toggle businessevent to Off, and click Save. (Refer back to the screenshot above.) In your terminal\u2019s $CRIBL_HOME/bin directory, shut down the server with: ./cribl stop That\u2019s it! Enjoy using Cribl\u00c2 Stream.\""
    },
    {
        "question_answer": {
            "question": "How can Cribl Stream be used to transform data?",
            "answer": "Cribl Stream provides various Functions that can be used to extract, manipulate, and enrich data.",
            "follow_up_question_1": "Can you give an example of a Function that can be used to enrich data?",
            "follow_up_answer_1": "The Eval Function can be used to add new fields to events and conditionally infer their values based on existing fields.",
            "follow_up_question_2": "Are there any Functions that can be used to remove unnecessary data?",
            "follow_up_answer_2": "Yes, the Drop Function can be used to filter out events that are not of interest for a particular downstream service.",
            "follow_up_question_3": "How can Cribl Stream help in reducing data volume?",
            "follow_up_answer_3": "By using Functions like Mask, Parser, and Drop, Cribl Stream can remove or obfuscate sensitive data, extract relevant fields, and filter out unnecessary events, resulting in a reduction in data volume.",
            "url": "https://docs.cribl.io/docs/getting-started-guide"
        },
        "reference": "Data tab, click Simple beside be_raw.log. This restores our preview of our original, unfiltered capture. We\u2019re ready to transform this sample data in more interesting ways, by building out our Pipeline\u2019s Functions. Functions are pieces of JavaScript code that Cribl\u00c2 Stream invokes on each event that passes through them. By\u00c2 default, this means all events \u00e2\u0080\u0093 each Function has a Filter field whose value defaults to true. As\u00c2 we just saw with data capture, you can replace this value with an expression that scopes the Function down to particular matching events. In this Pipeline, we\u2019ll use some of Cribl\u00c2 Stream\u2019s core Functions to: In the right Preview pane, notice each that event includes a social key, whose value is a (fictitious) raw Social Security number. Before this data goes any further through our Pipeline, let\u2019s use Cribl\u00c2 Stream\u2019s Mask Function to swap in an md5 hash of each SSN. In the left Pipelines pane, click Add\u00c2 Function. Search for Mask, then click it. In the new Function\u2019s Masking\u00c2 Rules, click the into Match\u00c2 Regex field. Now we want to build the Match\u00c2 Regex/Replace\u00c2 Expression row shown just below. Enter or paste this regex, which simply looks for the string social=, followed by any digits: (social=)(\\d+) In Replace\u00c2 Expression, paste the following hash function. The backticks are literal: `${g1}${C.Mask.md5(g2)}` Note that Apply to Fields defaults to _raw. This is what we want to target, so we\u2019ll accept this default. Click Save. You\u2019ll immediately notice some obvious changes: The Preview pane has switched from its IN to its OUT tab, to show you the outbound effect of the Pipeline you just saved. Each event\u2019s _raw field has changed color, to indicate that it\u2019s undergone some redactions. Now locate at least one event\u2019s Show\u00c2 more link, and click to expand it. You can verify that the social values have now been hashed. Having redacted sensitive data, we\u2019ll next use a Parser function to lift up all the _raw field\u2019s key-value pairs as fields: In the left Pipelines pane, click Add\u00c2 Function. Search for Parser, then click it. Leave the Operation\u00c2 Mode set to its Extract default. Set the Type to Key=Value Pairs. Leave the Source\u00c2 Field set to its _raw default. Click Save. You should see the Preview pane instantly light up with a lot more fields, parsed from _raw. You\u00c2 now have rich structured data, but not all of this data is particularly interesting: Note how many fields have NA (\u201cNot\u00c2 Applicable\u201d) values. We can enhance the Parser Function to ignore fields with NA values. In the Function\u2019s Fields Filter Expression field (near the bottom), enter this negation expression: value!='NA'. Note the single-quoted value. If you type (rather than paste) this expression, watch how typeahead matches the first quote you type. Click Save, and watch the Preview pane. Several fields should disappear \u00e2\u0080\u0093 such as credits, EventConversationID, and ReplyTo. The\u00c2 remaining fields should display meaningful values. Congratulations! Your log data is already starting to look better-organized and less bloated. If you didn\u2019t see the fields change, toggle the Parser Function Off, click Save below, and watch the Preview pane change. Using these toggles, you can preserve structure as you test and troubleshoot each Function\u2019s effect. Note that each Function also has a Final toggle, defaulting to Off. Enabling Final anywhere in the Functions stack will prevent data from flowing to any Functions lower in the UI. Be sure to toggle the Function back On, and click Save again, before you proceed! Next, let\u2019s add an extra field, and conditionally infer its value from existing values. We\u2019ll also remove the _raw field, now that it\u2019s redundant. To add and remove fields, the Eval Function is our pal. Let\u2019s assume we want to enrich our data by identifying the manufacturer of a certain popular phone handset. We can infer this from the existing phoneType field that we\u2019ve lifted up for each event. In the left Pipelines pane, click Add\u00c2 Function. Search for Eval, then click it. Click Add\u00c2 Field to open the Evaluate\u00c2 Fields table. Here you add new fields to events, defining each field as a key-value pair. If we needed more key-value pairs, we could click +\u00c2 Add\u00c2 Field for more rows. In the table\u2019s first row, click into the Name field and enter: phoneCompany. In the adjacent Value\u00c2 Expression field, enter this JS ternary expression that tests phoneType\u2019s value: phoneType.startsWith('iPhone') ? 'Apple' : 'Other' (Note the ? and : operators, and the single-quoted values.) Click Save. Examine some events in the Preview pane, and each should now contain a phoneCompany field that matches its phoneType. Now that we\u2019ve parsed out all of the _raw field\u2019s data \u00e2\u0080\u0093 it can go. Deleting a (large) redundant field will give us cleaner events, and reduced load on downstream resources. Still in the Eval Function, click into Remove\u00c2 Fields. Type: _raw and press Tab or Enter. Click Save. The Preview pane\u2019s diff view should now show each event\u2019s _raw field stripped out. Our log data has now been cleansed, structured, enriched, and slimmed-down. Let\u2019s next look at how to make it more legible, by giving fields simpler names. In the left Pipelines pane, click Add\u00c2 Function. This rhythm should now be familiar to you. Search for Rename, then click it. Click Add\u00c2 fields to open the Rename\u00c2 fields table. Click into the new Function\u2019s Rename\u00c2 fields table. This has the same structure you saw above in Eval: Each row defines a key-value pair. In Current\u00c2 name, enter the longhaired existing field name: conversationId. In New\u00c2 name, enter the simplified field name: ID. Watch any event\u2019s conversationId field in the Preview pane as you click Save at left. This\u00c2 field should change to ID in all events. We\u2019ve already refined our data substantially. To further slim it down, a Pipeline can entirely remove events that aren\u2019t of interest for a particular downstream service. As the \u201cPipeline\u201d name implies, your Cribl\u00c2 Stream installation can have multiple Pipelines, each configured to send out a data stream tailored to a particular Destination. This helps you get the right data in the right places most efficiently. Here, let\u2019s drop all events for customers who use prepaid monthly phone service (i.e., not postpaid): In the left Pipelines pane, click Add\u00c2 Function. Search for Drop, then click it. Click into the new Function\u2019s Filter field. Replace the default true value with this JS negation expression: accountType!='PostPaid' Click Save. Now scroll through the right Preview pane. Depending on your data sample, you should now see multiple events struck out and faded \u00e2\u0080\u0093 indicating that Cribl\u00c2 Stream will drop them before forwarding the data. Torture the data enough, and it will confess. By what factor have our transformations refined our data\u2019s volume? Let\u2019s check. In the right Preview pane, click the Basic\u00c2 Statistics button: Even without the removal of the _raw field (back in Eval) and the dropped events, you should see a substantial % reduction in the Full\u00c2 Event Length. Woo hoo! Before we wrap up our configuration: If you\u2019re curious about individual Functions\u2019 independent contribution to the data reduction shown here, you can test it now. Use the toggle\u00c2 Off\u00c2 > Save > Basic\u00c2 Statistics sequence to check various changes. We\u2019ve now built a complete, functional Pipeline. But so far, we\u2019ve tested its effects only on the static data sample we captured earlier. To get dynamic data flowing through a Pipeline, we need to filter that data in, by defining a Cribl\u00c2 Stream Route. At the Pipelines page\u2019s top left, click Attach to Route. This displays the Routes page. It\u2019s structured very similarly to the Pipelines page, so the rhythm here should feel familiar. Click Add\u00c2 Route. Enter a unique, meaningful Route Name, like demo. Leave the Filter field set to its true default, allowing it to deliver all events. Because a Route delivers events to a Pipeline, it offers a first stage of filtering. In\u00c2 production, you\u2019d typically configure each Route to filter events by appropriate source, sourcetype, index, host, _time, or other characteristics. The Filter field accepts JavaScript expressions, including AND (&&) and OR (||) operators. Set the Pipeline drop-down to our configured slicendice Pipeline. Leave the Enable Expression field set to its No default. Toggling this field to Yes changes the Output field to an Output Expression field where you can enter a JavaScript expression for your Destination name. Set the Output drop-down to either devnull or default. This doesn\u2019t matter, because we\u2019ve set default as a pointer to devnull. In\u00c2 production, you\u2019d set this carefully. You can leave the Description empty, and leave Final set to Yes. Grab the new Route by its left handle, and drag it above the default Route, so that our new Route will process events first. You should see something like the screenshot below. Click Save to save the new Route to the Routing table. If you\u2019re on Cribl.Cloud or any other distributed mode, click Commit\u00c2 &\u00c2 Deploy at Cribl\u00c2 Stream\u2019s upper right before proceeding. Then, in the resulting dialog box, click Commit\u00c2 &\u00c2 Deploy to confirm. You\u2019ll see a Commit\u00c2 successful message. The sparklines should immediately confirm that data is flowing through your new Route: To confirm data flow through the whole system we\u2019ve built, select Monitoring\u00c2 > Data > Routes and examine demo. Also select Monitoring\u00c2 > Data > Pipelines and examine slicendice. Look at you! Give yourself a pat on the back! In this short, scenic tour \u00e2\u0080\u0093 with no hit to your cloud-services charges \u00e2\u0080\u0093 you\u2019ve built a simple but complete Cribl\u00c2 Stream system, exercising all of its basic components: Interested in guided walk-throughs of more-advanced Cribl\u00c2 Stream features? We suggest that you next check out these further resources. Cribl\u00c2 Stream Sandboxes: Work through general and specific scenarios in a free, hosted environment, with terminal access and real data inputs and outputs. Distributed\u00c2 Quick\u00c2 Start: Building on this tutorial that you\u2019ve just completed, launch and configure a Cribl\u00c2 Stream distributed deployment. You\u2019ll work with a small but realistic model of a fully scaleable production deployment. Use Cases documentation: Bring your own services to build solutions to specific challenges. Cribl Concept: Pipelines \u00e2\u0080\u0093 Video showing how to build and use Pipelines at multiple Cribl\u00c2 Stream stages. Cribl Concept: Routing \u00e2\u0080\u0093 Video about using Routes to send different data through different paths. Oh yeah, you\u2019ve still got the Cribl\u00c2 Stream server running, with its businessevent.log datagen still firing events. If\u00c2 you\u2019d like to shut these down for now, in reverse order: Go to Data > Sources > Datagen. Toggle businessevent to Off, and click Save. (Refer back to the screenshot above.) In your terminal\u2019s $CRIBL_HOME/bin directory, shut down the server with: ./cribl stop That\u2019s it! Enjoy using Cribl\u00c2 Stream.\""
    },
    {
        "question_answer": {
            "question": "What are Routes in Cribl Stream?",
            "answer": "Routes in Cribl Stream are used to filter and route data to different Pipelines based on specified criteria.",
            "follow_up_question_1": "How can Routes be used to filter data?",
            "follow_up_answer_1": "Routes can be configured to filter events based on characteristics like source, sourcetype, index, host, or timestamp.",
            "follow_up_question_2": "What is the purpose of configuring Routes in Cribl Stream?",
            "follow_up_answer_2": "Configuring Routes allows users to send different data streams to different Pipelines, ensuring that the right data is delivered to the right destinations efficiently.",
            "follow_up_question_3": "Can Routes be used to drop events?",
            "follow_up_answer_3": "Yes, Routes can be configured to drop events that do not meet the specified criteria, preventing them from being forwarded to downstream services.",
            "url": "https://docs.cribl.io/docs/getting-started-guide"
        },
        "reference": "Data tab, click Simple beside be_raw.log. This restores our preview of our original, unfiltered capture. We\u2019re ready to transform this sample data in more interesting ways, by building out our Pipeline\u2019s Functions. Functions are pieces of JavaScript code that Cribl\u00c2 Stream invokes on each event that passes through them. By\u00c2 default, this means all events \u00e2\u0080\u0093 each Function has a Filter field whose value defaults to true. As\u00c2 we just saw with data capture, you can replace this value with an expression that scopes the Function down to particular matching events. In this Pipeline, we\u2019ll use some of Cribl\u00c2 Stream\u2019s core Functions to: In the right Preview pane, notice each that event includes a social key, whose value is a (fictitious) raw Social Security number. Before this data goes any further through our Pipeline, let\u2019s use Cribl\u00c2 Stream\u2019s Mask Function to swap in an md5 hash of each SSN. In the left Pipelines pane, click Add\u00c2 Function. Search for Mask, then click it. In the new Function\u2019s Masking\u00c2 Rules, click the into Match\u00c2 Regex field. Now we want to build the Match\u00c2 Regex/Replace\u00c2 Expression row shown just below. Enter or paste this regex, which simply looks for the string social=, followed by any digits: (social=)(\\d+) In Replace\u00c2 Expression, paste the following hash function. The backticks are literal: `${g1}${C.Mask.md5(g2)}` Note that Apply to Fields defaults to _raw. This is what we want to target, so we\u2019ll accept this default. Click Save. You\u2019ll immediately notice some obvious changes: The Preview pane has switched from its IN to its OUT tab, to show you the outbound effect of the Pipeline you just saved. Each event\u2019s _raw field has changed color, to indicate that it\u2019s undergone some redactions. Now locate at least one event\u2019s Show\u00c2 more link, and click to expand it. You can verify that the social values have now been hashed. Having redacted sensitive data, we\u2019ll next use a Parser function to lift up all the _raw field\u2019s key-value pairs as fields: In the left Pipelines pane, click Add\u00c2 Function. Search for Parser, then click it. Leave the Operation\u00c2 Mode set to its Extract default. Set the Type to Key=Value Pairs. Leave the Source\u00c2 Field set to its _raw default. Click Save. You should see the Preview pane instantly light up with a lot more fields, parsed from _raw. You\u00c2 now have rich structured data, but not all of this data is particularly interesting: Note how many fields have NA (\u201cNot\u00c2 Applicable\u201d) values. We can enhance the Parser Function to ignore fields with NA values. In the Function\u2019s Fields Filter Expression field (near the bottom), enter this negation expression: value!='NA'. Note the single-quoted value. If you type (rather than paste) this expression, watch how typeahead matches the first quote you type. Click Save, and watch the Preview pane. Several fields should disappear \u00e2\u0080\u0093 such as credits, EventConversationID, and ReplyTo. The\u00c2 remaining fields should display meaningful values. Congratulations! Your log data is already starting to look better-organized and less bloated. If you didn\u2019t see the fields change, toggle the Parser Function Off, click Save below, and watch the Preview pane change. Using these toggles, you can preserve structure as you test and troubleshoot each Function\u2019s effect. Note that each Function also has a Final toggle, defaulting to Off. Enabling Final anywhere in the Functions stack will prevent data from flowing to any Functions lower in the UI. Be sure to toggle the Function back On, and click Save again, before you proceed! Next, let\u2019s add an extra field, and conditionally infer its value from existing values. We\u2019ll also remove the _raw field, now that it\u2019s redundant. To add and remove fields, the Eval Function is our pal. Let\u2019s assume we want to enrich our data by identifying the manufacturer of a certain popular phone handset. We can infer this from the existing phoneType field that we\u2019ve lifted up for each event. In the left Pipelines pane, click Add\u00c2 Function. Search for Eval, then click it. Click Add\u00c2 Field to open the Evaluate\u00c2 Fields table. Here you add new fields to events, defining each field as a key-value pair. If we needed more key-value pairs, we could click +\u00c2 Add\u00c2 Field for more rows. In the table\u2019s first row, click into the Name field and enter: phoneCompany. In the adjacent Value\u00c2 Expression field, enter this JS ternary expression that tests phoneType\u2019s value: phoneType.startsWith('iPhone') ? 'Apple' : 'Other' (Note the ? and : operators, and the single-quoted values.) Click Save. Examine some events in the Preview pane, and each should now contain a phoneCompany field that matches its phoneType. Now that we\u2019ve parsed out all of the _raw field\u2019s data \u00e2\u0080\u0093 it can go. Deleting a (large) redundant field will give us cleaner events, and reduced load on downstream resources. Still in the Eval Function, click into Remove\u00c2 Fields. Type: _raw and press Tab or Enter. Click Save. The Preview pane\u2019s diff view should now show each event\u2019s _raw field stripped out. Our log data has now been cleansed, structured, enriched, and slimmed-down. Let\u2019s next look at how to make it more legible, by giving fields simpler names. In the left Pipelines pane, click Add\u00c2 Function. This rhythm should now be familiar to you. Search for Rename, then click it. Click Add\u00c2 fields to open the Rename\u00c2 fields table. Click into the new Function\u2019s Rename\u00c2 fields table. This has the same structure you saw above in Eval: Each row defines a key-value pair. In Current\u00c2 name, enter the longhaired existing field name: conversationId. In New\u00c2 name, enter the simplified field name: ID. Watch any event\u2019s conversationId field in the Preview pane as you click Save at left. This\u00c2 field should change to ID in all events. We\u2019ve already refined our data substantially. To further slim it down, a Pipeline can entirely remove events that aren\u2019t of interest for a particular downstream service. As the \u201cPipeline\u201d name implies, your Cribl\u00c2 Stream installation can have multiple Pipelines, each configured to send out a data stream tailored to a particular Destination. This helps you get the right data in the right places most efficiently. Here, let\u2019s drop all events for customers who use prepaid monthly phone service (i.e., not postpaid): In the left Pipelines pane, click Add\u00c2 Function. Search for Drop, then click it. Click into the new Function\u2019s Filter field. Replace the default true value with this JS negation expression: accountType!='PostPaid' Click Save. Now scroll through the right Preview pane. Depending on your data sample, you should now see multiple events struck out and faded \u00e2\u0080\u0093 indicating that Cribl\u00c2 Stream will drop them before forwarding the data. Torture the data enough, and it will confess. By what factor have our transformations refined our data\u2019s volume? Let\u2019s check. In the right Preview pane, click the Basic\u00c2 Statistics button: Even without the removal of the _raw field (back in Eval) and the dropped events, you should see a substantial % reduction in the Full\u00c2 Event Length. Woo hoo! Before we wrap up our configuration: If you\u2019re curious about individual Functions\u2019 independent contribution to the data reduction shown here, you can test it now. Use the toggle\u00c2 Off\u00c2 > Save > Basic\u00c2 Statistics sequence to check various changes. We\u2019ve now built a complete, functional Pipeline. But so far, we\u2019ve tested its effects only on the static data sample we captured earlier. To get dynamic data flowing through a Pipeline, we need to filter that data in, by defining a Cribl\u00c2 Stream Route. At the Pipelines page\u2019s top left, click Attach to Route. This displays the Routes page. It\u2019s structured very similarly to the Pipelines page, so the rhythm here should feel familiar. Click Add\u00c2 Route. Enter a unique, meaningful Route Name, like demo. Leave the Filter field set to its true default, allowing it to deliver all events. Because a Route delivers events to a Pipeline, it offers a first stage of filtering. In\u00c2 production, you\u2019d typically configure each Route to filter events by appropriate source, sourcetype, index, host, _time, or other characteristics. The Filter field accepts JavaScript expressions, including AND (&&) and OR (||) operators. Set the Pipeline drop-down to our configured slicendice Pipeline. Leave the Enable Expression field set to its No default. Toggling this field to Yes changes the Output field to an Output Expression field where you can enter a JavaScript expression for your Destination name. Set the Output drop-down to either devnull or default. This doesn\u2019t matter, because we\u2019ve set default as a pointer to devnull. In\u00c2 production, you\u2019d set this carefully. You can leave the Description empty, and leave Final set to Yes. Grab the new Route by its left handle, and drag it above the default Route, so that our new Route will process events first. You should see something like the screenshot below. Click Save to save the new Route to the Routing table. If you\u2019re on Cribl.Cloud or any other distributed mode, click Commit\u00c2 &\u00c2 Deploy at Cribl\u00c2 Stream\u2019s upper right before proceeding. Then, in the resulting dialog box, click Commit\u00c2 &\u00c2 Deploy to confirm. You\u2019ll see a Commit\u00c2 successful message. The sparklines should immediately confirm that data is flowing through your new Route: To confirm data flow through the whole system we\u2019ve built, select Monitoring\u00c2 > Data > Routes and examine demo. Also select Monitoring\u00c2 > Data > Pipelines and examine slicendice. Look at you! Give yourself a pat on the back! In this short, scenic tour \u00e2\u0080\u0093 with no hit to your cloud-services charges \u00e2\u0080\u0093 you\u2019ve built a simple but complete Cribl\u00c2 Stream system, exercising all of its basic components: Interested in guided walk-throughs of more-advanced Cribl\u00c2 Stream features? We suggest that you next check out these further resources. Cribl\u00c2 Stream Sandboxes: Work through general and specific scenarios in a free, hosted environment, with terminal access and real data inputs and outputs. Distributed\u00c2 Quick\u00c2 Start: Building on this tutorial that you\u2019ve just completed, launch and configure a Cribl\u00c2 Stream distributed deployment. You\u2019ll work with a small but realistic model of a fully scaleable production deployment. Use Cases documentation: Bring your own services to build solutions to specific challenges. Cribl Concept: Pipelines \u00e2\u0080\u0093 Video showing how to build and use Pipelines at multiple Cribl\u00c2 Stream stages. Cribl Concept: Routing \u00e2\u0080\u0093 Video about using Routes to send different data through different paths. Oh yeah, you\u2019ve still got the Cribl\u00c2 Stream server running, with its businessevent.log datagen still firing events. If\u00c2 you\u2019d like to shut these down for now, in reverse order: Go to Data > Sources > Datagen. Toggle businessevent to Off, and click Save. (Refer back to the screenshot above.) In your terminal\u2019s $CRIBL_HOME/bin directory, shut down the server with: ./cribl stop That\u2019s it! Enjoy using Cribl\u00c2 Stream.\""
    },
    {
        "question_answer": {
            "question": "What is Cribl Stream?",
            "answer": "Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure.",
            "follow_up_question_1": "How does Cribl Stream help with data collection?",
            "follow_up_answer_1": "Cribl Stream allows you to collect data from any source, regardless of its format or location. It provides the necessary tools to ingest and process data from various systems and applications.",
            "follow_up_question_2": "Can Cribl Stream handle large volumes of data?",
            "follow_up_answer_2": "Yes, Cribl Stream is designed to handle high volumes of data. It is highly scalable and can process large amounts of data in real-time.",
            "follow_up_question_3": "What are some benefits of using Cribl Stream for data routing?",
            "follow_up_answer_3": "Cribl Stream allows you to route data to any destination within your existing data infrastructure. This flexibility enables you to send data to the appropriate systems for further analysis or storage.",
            "follow_up_question_4": "How does Cribl Stream ensure data normalization?",
            "follow_up_answer_4": "Cribl Stream provides tools to normalize data from different sources. It allows you to transform and standardize data formats, making it easier to analyze and compare across different systems.",
            "url": "https://cribl.io/support"
        },
        "reference": "url,title,text_chunks https://cribl.io/support,Cribl Stream and Edge Observability Pipeline Support | Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. Guides to help you get started with Cribl Stream, Edge, and Search When you want to do it yourselfaka RTFM A Cribl Community Slack channel so you can connect with other users. Need a login? FREE Cribl training and official certification center The place to ask questions, find answers, and share best practices Step-by-step guidance to help prove the value of your use cases An intro to basic concepts and commonly used functions for Cribl Stream GitHub repos for updated demo and training content Docker hub for the latest published Cribl Stream containers Cribl\u2019s Customer Success team is designed to guide, shape, and advise you throughout your entire journey with Cribl. Exchange ideas and craft a flight path toward success. Throttle up as we accelerate through implementation. Destination is reached when you unlock the value of all your observability data with Cribl. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    },
    {
        "question_answer": {
            "question": "What is Cribl Edge?",
            "answer": "Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data.",
            "follow_up_question_1": "How does Cribl Edge differ from Cribl Stream?",
            "follow_up_answer_1": "While Cribl Stream focuses on data collection, reduction, enrichment, normalization, and routing within your existing data infrastructure, Cribl Edge is specifically designed for edge-based data collection. It allows you to collect data directly from edge devices or remote locations.",
            "follow_up_question_2": "What types of data can Cribl Edge collect?",
            "follow_up_answer_2": "Cribl Edge can collect logs, metrics, and application data from various sources. It is designed to handle different types of data generated by edge devices or remote systems.",
            "follow_up_question_3": "How does Cribl Edge ensure scalability?",
            "follow_up_answer_3": "Cribl Edge is highly scalable and can handle large volumes of data. It is designed to efficiently collect and process data from edge devices or remote locations, ensuring scalability and performance.",
            "follow_up_question_4": "Can Cribl Edge integrate with other observability tools?",
            "follow_up_answer_4": "Yes, Cribl Edge can integrate with other observability tools. It allows you to route data to different destinations, including other observability platforms or systems for further analysis.",
            "url": "https://cribl.io/support"
        },
        "reference": "url,title,text_chunks https://cribl.io/support,Cribl Stream and Edge Observability Pipeline Support | Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. Guides to help you get started with Cribl Stream, Edge, and Search When you want to do it yourselfaka RTFM A Cribl Community Slack channel so you can connect with other users. Need a login? FREE Cribl training and official certification center The place to ask questions, find answers, and share best practices Step-by-step guidance to help prove the value of your use cases An intro to basic concepts and commonly used functions for Cribl Stream GitHub repos for updated demo and training content Docker hub for the latest published Cribl Stream containers Cribl\u2019s Customer Success team is designed to guide, shape, and advise you throughout your entire journey with Cribl. Exchange ideas and craft a flight path toward success. Throttle up as we accelerate through implementation. Destination is reached when you unlock the value of all your observability data with Cribl. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    },
    {
        "question_answer": {
            "question": "What is Cribl Search?",
            "answer": "Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first.",
            "follow_up_question_1": "How does Cribl Search improve the search process?",
            "follow_up_answer_1": "Cribl Search eliminates the need to collect and store data before searching. It allows users to directly search data in its original location, saving time and resources.",
            "follow_up_question_2": "Can Cribl Search handle large volumes of data?",
            "follow_up_answer_2": "Yes, Cribl Search is designed to handle large volumes of data. It leverages efficient search algorithms and indexing techniques to provide fast and accurate search results.",
            "follow_up_question_3": "What are the benefits of searching data in place?",
            "follow_up_answer_3": "Searching data in place eliminates the need for data duplication and storage. It reduces the complexity and cost associated with data management and allows users to access real-time data without delays.",
            "follow_up_question_4": "How does Cribl Search ensure data security?",
            "follow_up_answer_4": "Cribl Search provides security features to ensure data privacy and protection. It allows you to define access controls and permissions, ensuring that only authorized users can search and access the data.",
            "url": "https://cribl.io/support"
        },
        "reference": "url,title,text_chunks https://cribl.io/support,Cribl Stream and Edge Observability Pipeline Support | Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. Guides to help you get started with Cribl Stream, Edge, and Search When you want to do it yourselfaka RTFM A Cribl Community Slack channel so you can connect with other users. Need a login? FREE Cribl training and official certification center The place to ask questions, find answers, and share best practices Step-by-step guidance to help prove the value of your use cases An intro to basic concepts and commonly used functions for Cribl Stream GitHub repos for updated demo and training content Docker hub for the latest published Cribl Stream containers Cribl\u2019s Customer Success team is designed to guide, shape, and advise you throughout your entire journey with Cribl. Exchange ideas and craft a flight path toward success. Throttle up as we accelerate through implementation. Destination is reached when you unlock the value of all your observability data with Cribl. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    },
    {
        "question_answer": {
            "question": "What is the purpose of moving the Default Mappings rule to the bottom of the Ruleset?",
            "answer": "Moving the Default Mappings rule to the bottom of the Ruleset reflects its catch-all function. This ensures that it is the last rule to be applied, allowing it to handle any data that does not match the criteria of the preceding rules.",
            "follow_up_question_1": "Why is it important to have a catch-all rule?",
            "follow_up_answer_1": "Having a catch-all rule is important because it ensures that no data is left unhandled. If there are no rules that match a specific data, the catch-all rule will take care of it.",
            "follow_up_question_2": "Are there any potential drawbacks of using a catch-all rule?",
            "follow_up_answer_2": "One potential drawback of using a catch-all rule is that it may result in some data being incorrectly mapped or processed. It is important to regularly review and update the ruleset to minimize any potential issues.",
            "follow_up_question_3": "How can I ensure that the catch-all rule is working correctly?",
            "follow_up_answer_3": "To ensure that the catch-all rule is working correctly, you can monitor the data that is being processed by it. If you notice any unexpected mappings or issues, you can adjust the ruleset accordingly.",
            "url": "https://docs.cribl.io/stream/distributed-guide"
        },
        "reference": "below: Move the Default\u00c2 Mappings rule to the bottom of the Ruleset, reflecting its catch-all function. Click Save to store the new configuration. Confirm the warning that changes will take effect immediately. We now have two data Sources and two Worker\u00c2 Groups \u00e2\u0080\u0093 one each for (Web) logs versus (Cribl Internal) metrics \u00e2\u0080\u0093 along with two Mapping Rules to map data accordingly. To\u00c2 confirm the Workers\u2019 assignment to the two Groups, click the top nav\u2019s Manage tab, then select Groups from the submenu: To confirm further details about the Workers, click the Workers tab, and on the resulting Workers page, click anywhere on the Worker Node\u2019s row to reveal more details: With incoming metrics now mapped to our second Worker\u00c2 Group, we next need to configure this Group\u2019s output. Here, we\u2019ll rely on a metrics-oriented Pipeline and a Destination that ship with Cribl\u00c2 Stream, and create a new Route to connect everything up. From the Leader\u2019s top nav, click Manage\u00c2 > Groups > CriblMetrics. From the resulting submenu, select Processing\u00c2 > Pipelines. On the Pipelines page, find the cribl_metrics_rollup Pipeline, and click it to expand it. Expand this Pipeline\u2019s Functions (including Comments) to see its configuration. It\u2019s preconfigured with a Rollup\u00c2 Metrics Function to aggregate metrics to a 30-second time window. Next is an Eval Function that filters for Cribl (Cribl\u00c2 Stream) internal metrics and tags them on outgoing events with a new field. We\u2019ll connect this existing Pipeline to a new Route: At the Pipelines page\u2019s top left, click Attach to Route.This displays the Data Routes page. Click Add\u00c2 Route. Enter a unique Route Name, like metrics. Leave the Filter field set to its true default, allowing it to deliver all events. Make sure the Pipeline drop-down is set to cribl_metrics_rollup. As the Output (Destination), select our old friend devnull:devnull. This is Cribl\u00c2 Stream\u2019s preconfigured Destination that simulates a downstream service while simply dropping events. You can leave the Description empty, and leave Final set to Yes. Grab the new Route by its handle, and drag it to the top of the Routing table, so that our new Route will process events first. You should see something like the screenshot below. Click Save to save the new Route configuration. Commit and Deploy your changes. From the sparkline on the Route you just configured (see the screenshot above), you can already see that metrics data is flowing all the way \u201cout\u201d of Cribl\u00c2 Stream \u00e2\u0080\u0093 simulated here by the DevNull Destination. To\u00c2 verify the whole configuration you\u2019ve created, click the top nav\u2019s Monitoring tab. On the Monitoring page, toggle the All\u00c2 Groups drop-down (upper right), toggle between the two Worker\u00c2 Groups to see the division of labor: Before a final section where you can tear down your infrastructure, here\u2019s a recap of the simple (but expandable) distributed model we\u2019ve created, with some ideas for expanding it: A distributed deployment enables Cribl\u00c2 Stream to scale out to higher data volumes. This load-balancing occurs even with a single Worker\u00c2 Group, in which all Workers share the same configuration. By adding multiple Worker Groups, you can partition Worker\u00c2 Nodes (and their data flows) by different configurations. In this demonstration, we simply mapped Workers to Groups by the Workers\u2019 hostname. But\u00c2 you can map by a range of arbitrary criteria to meet your production needs. E.g.: Different Groups can be managed by different teams. You can filter on DNS rules to send relevant data to the relevant team\u2019s Group. Different Groups can also maintain configurations for different regions\u2019 data privacy or data retention requirements. You can also Map workers arbitrarily using Tags and other options. Cribl\u00c2 Stream refers to \u201cWorkers\u201d at several levels. Now that you\u2019ve been initiated into building distributed deployments, here\u2019s a guide to the fine points of distinguishing these levels: A Worker\u00c2 Group holds one or multiple Worker Nodes. Each Worker\u00c2 Node functions like an independent Cribl\u00c2 Stream single-instance deployment. Worker\u00c2 Nodes don\u2019t coordinate directly with each other \u00e2\u0080\u0093 they\u2019re coordinated only through communication to/from the Leader\u00c2 Node. Each Worker\u00c2 Node contains a configured number of Worker Processes. Unlike the above grouping abstractions, this is the level that actually processes data. To load-balance among Worker\u00c2 Processes, Cribl\u00c2 Stream\u2019s API\u00c2 Process round-robins incoming connections to them. When deploying on AWS/EKS, Worker Groups should not span Availability\u00c2 Zones. If you have EBS persistent volumes, and a node fails, its replacement won\u2019t be able to access the peer volume across AZs. If and when you choose to shut down the infrastructure you\u2019ve configured for this demonstration: Navigate to Cribl\u00c2 Stream\u2019s default Group\u00c2 > Data\u00c2 > Sources\u00c2 > Datagen, and switch off the toggle beside weblog.log. If you configured a second Worker Group: Navigate to Cribl\u00c2 Stream\u2019s CriblMetrics Group\u00c2 > Data\u00c2 > Sources\u00c2 > Cribl\u00c2 Internal, and disable the toggle beside CriblMetrics. If you have netcat running on a Worker\u2019s terminal/console, ^C it. There\u2019s no need (or way) to switch off the DevNull Destination \u00e2\u0080\u0093 it just is. If desired, Commit and Deploy these changes. If you\u2019re running the Cribl\u00c2 Stream server(s) on cloud instances that will (ultimately) incur charges, you\u2019re now free to shut down those cloud resources. Interested in guided walk-throughs of more-advanced Cribl\u00c2 Stream features? We suggest that you next check out these further resources. Distributed Deployment: All the details behind the deployment approach you just mastered in this tutorial. Cribl\u00c2 Stream Sandboxes: Work through general and specific scenarios in a free, hosted environment, with terminal access and real data inputs and outputs. Use Cases documentation: Bring your own services to build solutions to specific challenges. Cribl Concept: Pipelines \u00e2\u0080\u0093 Video showing how to build and use Pipelines at multiple Cribl\u00c2 Stream stages. Cribl Concept: Routing \u00e2\u0080\u0093 Video about using Routes to send different data through different paths.\""
    },
    {
        "question_answer": {
            "question": "What is the purpose of the cribl_metrics_rollup Pipeline?",
            "answer": "The cribl_metrics_rollup Pipeline is designed to aggregate metrics to a 30-second time window. It helps in summarizing and organizing the metrics data for further analysis and processing.",
            "follow_up_question_1": "How does the cribl_metrics_rollup Pipeline aggregate the metrics?",
            "follow_up_answer_1": "The cribl_metrics_rollup Pipeline uses a Rollup Metrics Function to aggregate the metrics to a 30-second time window. This function combines and summarizes the metrics data within each time window.",
            "follow_up_question_2": "What are the benefits of aggregating metrics?",
            "follow_up_answer_2": "Aggregating metrics provides a more concise and manageable representation of the data. It helps in identifying trends, patterns, and anomalies in the metrics over time.",
            "follow_up_question_3": "Can I customize the time window for aggregating metrics?",
            "follow_up_answer_3": "Yes, you can customize the time window for aggregating metrics in the cribl_metrics_rollup Pipeline. By adjusting the configuration of the Rollup Metrics Function, you can specify the desired time window.",
            "url": "https://docs.cribl.io/stream/distributed-guide"
        },
        "reference": "below: Move the Default\u00c2 Mappings rule to the bottom of the Ruleset, reflecting its catch-all function. Click Save to store the new configuration. Confirm the warning that changes will take effect immediately. We now have two data Sources and two Worker\u00c2 Groups \u00e2\u0080\u0093 one each for (Web) logs versus (Cribl Internal) metrics \u00e2\u0080\u0093 along with two Mapping Rules to map data accordingly. To\u00c2 confirm the Workers\u2019 assignment to the two Groups, click the top nav\u2019s Manage tab, then select Groups from the submenu: To confirm further details about the Workers, click the Workers tab, and on the resulting Workers page, click anywhere on the Worker Node\u2019s row to reveal more details: With incoming metrics now mapped to our second Worker\u00c2 Group, we next need to configure this Group\u2019s output. Here, we\u2019ll rely on a metrics-oriented Pipeline and a Destination that ship with Cribl\u00c2 Stream, and create a new Route to connect everything up. From the Leader\u2019s top nav, click Manage\u00c2 > Groups > CriblMetrics. From the resulting submenu, select Processing\u00c2 > Pipelines. On the Pipelines page, find the cribl_metrics_rollup Pipeline, and click it to expand it. Expand this Pipeline\u2019s Functions (including Comments) to see its configuration. It\u2019s preconfigured with a Rollup\u00c2 Metrics Function to aggregate metrics to a 30-second time window. Next is an Eval Function that filters for Cribl (Cribl\u00c2 Stream) internal metrics and tags them on outgoing events with a new field. We\u2019ll connect this existing Pipeline to a new Route: At the Pipelines page\u2019s top left, click Attach to Route.This displays the Data Routes page. Click Add\u00c2 Route. Enter a unique Route Name, like metrics. Leave the Filter field set to its true default, allowing it to deliver all events. Make sure the Pipeline drop-down is set to cribl_metrics_rollup. As the Output (Destination), select our old friend devnull:devnull. This is Cribl\u00c2 Stream\u2019s preconfigured Destination that simulates a downstream service while simply dropping events. You can leave the Description empty, and leave Final set to Yes. Grab the new Route by its handle, and drag it to the top of the Routing table, so that our new Route will process events first. You should see something like the screenshot below. Click Save to save the new Route configuration. Commit and Deploy your changes. From the sparkline on the Route you just configured (see the screenshot above), you can already see that metrics data is flowing all the way \u201cout\u201d of Cribl\u00c2 Stream \u00e2\u0080\u0093 simulated here by the DevNull Destination. To\u00c2 verify the whole configuration you\u2019ve created, click the top nav\u2019s Monitoring tab. On the Monitoring page, toggle the All\u00c2 Groups drop-down (upper right), toggle between the two Worker\u00c2 Groups to see the division of labor: Before a final section where you can tear down your infrastructure, here\u2019s a recap of the simple (but expandable) distributed model we\u2019ve created, with some ideas for expanding it: A distributed deployment enables Cribl\u00c2 Stream to scale out to higher data volumes. This load-balancing occurs even with a single Worker\u00c2 Group, in which all Workers share the same configuration. By adding multiple Worker Groups, you can partition Worker\u00c2 Nodes (and their data flows) by different configurations. In this demonstration, we simply mapped Workers to Groups by the Workers\u2019 hostname. But\u00c2 you can map by a range of arbitrary criteria to meet your production needs. E.g.: Different Groups can be managed by different teams. You can filter on DNS rules to send relevant data to the relevant team\u2019s Group. Different Groups can also maintain configurations for different regions\u2019 data privacy or data retention requirements. You can also Map workers arbitrarily using Tags and other options. Cribl\u00c2 Stream refers to \u201cWorkers\u201d at several levels. Now that you\u2019ve been initiated into building distributed deployments, here\u2019s a guide to the fine points of distinguishing these levels: A Worker\u00c2 Group holds one or multiple Worker Nodes. Each Worker\u00c2 Node functions like an independent Cribl\u00c2 Stream single-instance deployment. Worker\u00c2 Nodes don\u2019t coordinate directly with each other \u00e2\u0080\u0093 they\u2019re coordinated only through communication to/from the Leader\u00c2 Node. Each Worker\u00c2 Node contains a configured number of Worker Processes. Unlike the above grouping abstractions, this is the level that actually processes data. To load-balance among Worker\u00c2 Processes, Cribl\u00c2 Stream\u2019s API\u00c2 Process round-robins incoming connections to them. When deploying on AWS/EKS, Worker Groups should not span Availability\u00c2 Zones. If you have EBS persistent volumes, and a node fails, its replacement won\u2019t be able to access the peer volume across AZs. If and when you choose to shut down the infrastructure you\u2019ve configured for this demonstration: Navigate to Cribl\u00c2 Stream\u2019s default Group\u00c2 > Data\u00c2 > Sources\u00c2 > Datagen, and switch off the toggle beside weblog.log. If you configured a second Worker Group: Navigate to Cribl\u00c2 Stream\u2019s CriblMetrics Group\u00c2 > Data\u00c2 > Sources\u00c2 > Cribl\u00c2 Internal, and disable the toggle beside CriblMetrics. If you have netcat running on a Worker\u2019s terminal/console, ^C it. There\u2019s no need (or way) to switch off the DevNull Destination \u00e2\u0080\u0093 it just is. If desired, Commit and Deploy these changes. If you\u2019re running the Cribl\u00c2 Stream server(s) on cloud instances that will (ultimately) incur charges, you\u2019re now free to shut down those cloud resources. Interested in guided walk-throughs of more-advanced Cribl\u00c2 Stream features? We suggest that you next check out these further resources. Distributed Deployment: All the details behind the deployment approach you just mastered in this tutorial. Cribl\u00c2 Stream Sandboxes: Work through general and specific scenarios in a free, hosted environment, with terminal access and real data inputs and outputs. Use Cases documentation: Bring your own services to build solutions to specific challenges. Cribl Concept: Pipelines \u00e2\u0080\u0093 Video showing how to build and use Pipelines at multiple Cribl\u00c2 Stream stages. Cribl Concept: Routing \u00e2\u0080\u0093 Video about using Routes to send different data through different paths.\""
    },
    {
        "question_answer": {
            "question": "What is the purpose of the devnull:devnull Destination?",
            "answer": "The devnull:devnull Destination is a preconfigured Destination in Cribl Stream that simulates a downstream service while simply dropping events. It is commonly used for testing or when there is no need to send the events to an actual destination.",
            "follow_up_question_1": "Can I use a different Destination instead of devnull:devnull?",
            "follow_up_answer_1": "Yes, you can use a different Destination instead of devnull:devnull. Cribl Stream provides various preconfigured Destinations, and you can also configure custom Destinations to suit your specific needs.",
            "follow_up_question_2": "What happens to the events that are sent to the devnull:devnull Destination?",
            "follow_up_answer_2": "The events that are sent to the devnull:devnull Destination are simply dropped and not processed further. They do not reach any actual downstream service or destination.",
            "follow_up_question_3": "Is there a way to monitor the events that are sent to the devnull:devnull Destination?",
            "follow_up_answer_3": "Since the devnull:devnull Destination simply drops events, there is no specific monitoring or logging of the events sent to it. If you need to monitor or track the events, you can consider using a different Destination or configuring custom logging or monitoring mechanisms.",
            "url": "https://docs.cribl.io/stream/distributed-guide"
        },
        "reference": "below: Move the Default\u00c2 Mappings rule to the bottom of the Ruleset, reflecting its catch-all function. Click Save to store the new configuration. Confirm the warning that changes will take effect immediately. We now have two data Sources and two Worker\u00c2 Groups \u00e2\u0080\u0093 one each for (Web) logs versus (Cribl Internal) metrics \u00e2\u0080\u0093 along with two Mapping Rules to map data accordingly. To\u00c2 confirm the Workers\u2019 assignment to the two Groups, click the top nav\u2019s Manage tab, then select Groups from the submenu: To confirm further details about the Workers, click the Workers tab, and on the resulting Workers page, click anywhere on the Worker Node\u2019s row to reveal more details: With incoming metrics now mapped to our second Worker\u00c2 Group, we next need to configure this Group\u2019s output. Here, we\u2019ll rely on a metrics-oriented Pipeline and a Destination that ship with Cribl\u00c2 Stream, and create a new Route to connect everything up. From the Leader\u2019s top nav, click Manage\u00c2 > Groups > CriblMetrics. From the resulting submenu, select Processing\u00c2 > Pipelines. On the Pipelines page, find the cribl_metrics_rollup Pipeline, and click it to expand it. Expand this Pipeline\u2019s Functions (including Comments) to see its configuration. It\u2019s preconfigured with a Rollup\u00c2 Metrics Function to aggregate metrics to a 30-second time window. Next is an Eval Function that filters for Cribl (Cribl\u00c2 Stream) internal metrics and tags them on outgoing events with a new field. We\u2019ll connect this existing Pipeline to a new Route: At the Pipelines page\u2019s top left, click Attach to Route.This displays the Data Routes page. Click Add\u00c2 Route. Enter a unique Route Name, like metrics. Leave the Filter field set to its true default, allowing it to deliver all events. Make sure the Pipeline drop-down is set to cribl_metrics_rollup. As the Output (Destination), select our old friend devnull:devnull. This is Cribl\u00c2 Stream\u2019s preconfigured Destination that simulates a downstream service while simply dropping events. You can leave the Description empty, and leave Final set to Yes. Grab the new Route by its handle, and drag it to the top of the Routing table, so that our new Route will process events first. You should see something like the screenshot below. Click Save to save the new Route configuration. Commit and Deploy your changes. From the sparkline on the Route you just configured (see the screenshot above), you can already see that metrics data is flowing all the way \u201cout\u201d of Cribl\u00c2 Stream \u00e2\u0080\u0093 simulated here by the DevNull Destination. To\u00c2 verify the whole configuration you\u2019ve created, click the top nav\u2019s Monitoring tab. On the Monitoring page, toggle the All\u00c2 Groups drop-down (upper right), toggle between the two Worker\u00c2 Groups to see the division of labor: Before a final section where you can tear down your infrastructure, here\u2019s a recap of the simple (but expandable) distributed model we\u2019ve created, with some ideas for expanding it: A distributed deployment enables Cribl\u00c2 Stream to scale out to higher data volumes. This load-balancing occurs even with a single Worker\u00c2 Group, in which all Workers share the same configuration. By adding multiple Worker Groups, you can partition Worker\u00c2 Nodes (and their data flows) by different configurations. In this demonstration, we simply mapped Workers to Groups by the Workers\u2019 hostname. But\u00c2 you can map by a range of arbitrary criteria to meet your production needs. E.g.: Different Groups can be managed by different teams. You can filter on DNS rules to send relevant data to the relevant team\u2019s Group. Different Groups can also maintain configurations for different regions\u2019 data privacy or data retention requirements. You can also Map workers arbitrarily using Tags and other options. Cribl\u00c2 Stream refers to \u201cWorkers\u201d at several levels. Now that you\u2019ve been initiated into building distributed deployments, here\u2019s a guide to the fine points of distinguishing these levels: A Worker\u00c2 Group holds one or multiple Worker Nodes. Each Worker\u00c2 Node functions like an independent Cribl\u00c2 Stream single-instance deployment. Worker\u00c2 Nodes don\u2019t coordinate directly with each other \u00e2\u0080\u0093 they\u2019re coordinated only through communication to/from the Leader\u00c2 Node. Each Worker\u00c2 Node contains a configured number of Worker Processes. Unlike the above grouping abstractions, this is the level that actually processes data. To load-balance among Worker\u00c2 Processes, Cribl\u00c2 Stream\u2019s API\u00c2 Process round-robins incoming connections to them. When deploying on AWS/EKS, Worker Groups should not span Availability\u00c2 Zones. If you have EBS persistent volumes, and a node fails, its replacement won\u2019t be able to access the peer volume across AZs. If and when you choose to shut down the infrastructure you\u2019ve configured for this demonstration: Navigate to Cribl\u00c2 Stream\u2019s default Group\u00c2 > Data\u00c2 > Sources\u00c2 > Datagen, and switch off the toggle beside weblog.log. If you configured a second Worker Group: Navigate to Cribl\u00c2 Stream\u2019s CriblMetrics Group\u00c2 > Data\u00c2 > Sources\u00c2 > Cribl\u00c2 Internal, and disable the toggle beside CriblMetrics. If you have netcat running on a Worker\u2019s terminal/console, ^C it. There\u2019s no need (or way) to switch off the DevNull Destination \u00e2\u0080\u0093 it just is. If desired, Commit and Deploy these changes. If you\u2019re running the Cribl\u00c2 Stream server(s) on cloud instances that will (ultimately) incur charges, you\u2019re now free to shut down those cloud resources. Interested in guided walk-throughs of more-advanced Cribl\u00c2 Stream features? We suggest that you next check out these further resources. Distributed Deployment: All the details behind the deployment approach you just mastered in this tutorial. Cribl\u00c2 Stream Sandboxes: Work through general and specific scenarios in a free, hosted environment, with terminal access and real data inputs and outputs. Use Cases documentation: Bring your own services to build solutions to specific challenges. Cribl Concept: Pipelines \u00e2\u0080\u0093 Video showing how to build and use Pipelines at multiple Cribl\u00c2 Stream stages. Cribl Concept: Routing \u00e2\u0080\u0093 Video about using Routes to send different data through different paths.\""
    },
    {
        "question_answer": {
            "question": "What is the purpose of a distributed deployment in Cribl Stream?",
            "answer": "A distributed deployment enables Cribl Stream to scale out to higher data volumes. It allows for load-balancing and partitioning of data flows across multiple Worker Groups and Worker Nodes.",
            "follow_up_question_1": "How does a distributed deployment help in handling higher data volumes?",
            "follow_up_answer_1": "In a distributed deployment, the data flows are distributed across multiple Worker Groups and Worker Nodes. This allows for parallel processing and load-balancing, which helps in handling higher data volumes more efficiently.",
            "follow_up_question_2": "Can you provide an example of how load-balancing occurs in a distributed deployment?",
            "follow_up_answer_2": "In a distributed deployment, Cribl Stream's API Process round-robins incoming connections to the Worker Processes. This ensures that the data is evenly distributed among the Worker Nodes, enabling load-balancing.",
            "follow_up_question_3": "Are there any considerations for deploying Cribl Stream on cloud instances?",
            "follow_up_answer_3": "When deploying Cribl Stream on cloud instances, it is recommended to avoid spanning Worker Groups across Availability Zones. This helps in ensuring data availability and access, especially if there are EBS persistent volumes involved.",
            "url": "https://docs.cribl.io/stream/distributed-guide"
        },
        "reference": "below: Move the Default\u00c2 Mappings rule to the bottom of the Ruleset, reflecting its catch-all function. Click Save to store the new configuration. Confirm the warning that changes will take effect immediately. We now have two data Sources and two Worker\u00c2 Groups \u00e2\u0080\u0093 one each for (Web) logs versus (Cribl Internal) metrics \u00e2\u0080\u0093 along with two Mapping Rules to map data accordingly. To\u00c2 confirm the Workers\u2019 assignment to the two Groups, click the top nav\u2019s Manage tab, then select Groups from the submenu: To confirm further details about the Workers, click the Workers tab, and on the resulting Workers page, click anywhere on the Worker Node\u2019s row to reveal more details: With incoming metrics now mapped to our second Worker\u00c2 Group, we next need to configure this Group\u2019s output. Here, we\u2019ll rely on a metrics-oriented Pipeline and a Destination that ship with Cribl\u00c2 Stream, and create a new Route to connect everything up. From the Leader\u2019s top nav, click Manage\u00c2 > Groups > CriblMetrics. From the resulting submenu, select Processing\u00c2 > Pipelines. On the Pipelines page, find the cribl_metrics_rollup Pipeline, and click it to expand it. Expand this Pipeline\u2019s Functions (including Comments) to see its configuration. It\u2019s preconfigured with a Rollup\u00c2 Metrics Function to aggregate metrics to a 30-second time window. Next is an Eval Function that filters for Cribl (Cribl\u00c2 Stream) internal metrics and tags them on outgoing events with a new field. We\u2019ll connect this existing Pipeline to a new Route: At the Pipelines page\u2019s top left, click Attach to Route.This displays the Data Routes page. Click Add\u00c2 Route. Enter a unique Route Name, like metrics. Leave the Filter field set to its true default, allowing it to deliver all events. Make sure the Pipeline drop-down is set to cribl_metrics_rollup. As the Output (Destination), select our old friend devnull:devnull. This is Cribl\u00c2 Stream\u2019s preconfigured Destination that simulates a downstream service while simply dropping events. You can leave the Description empty, and leave Final set to Yes. Grab the new Route by its handle, and drag it to the top of the Routing table, so that our new Route will process events first. You should see something like the screenshot below. Click Save to save the new Route configuration. Commit and Deploy your changes. From the sparkline on the Route you just configured (see the screenshot above), you can already see that metrics data is flowing all the way \u201cout\u201d of Cribl\u00c2 Stream \u00e2\u0080\u0093 simulated here by the DevNull Destination. To\u00c2 verify the whole configuration you\u2019ve created, click the top nav\u2019s Monitoring tab. On the Monitoring page, toggle the All\u00c2 Groups drop-down (upper right), toggle between the two Worker\u00c2 Groups to see the division of labor: Before a final section where you can tear down your infrastructure, here\u2019s a recap of the simple (but expandable) distributed model we\u2019ve created, with some ideas for expanding it: A distributed deployment enables Cribl\u00c2 Stream to scale out to higher data volumes. This load-balancing occurs even with a single Worker\u00c2 Group, in which all Workers share the same configuration. By adding multiple Worker Groups, you can partition Worker\u00c2 Nodes (and their data flows) by different configurations. In this demonstration, we simply mapped Workers to Groups by the Workers\u2019 hostname. But\u00c2 you can map by a range of arbitrary criteria to meet your production needs. E.g.: Different Groups can be managed by different teams. You can filter on DNS rules to send relevant data to the relevant team\u2019s Group. Different Groups can also maintain configurations for different regions\u2019 data privacy or data retention requirements. You can also Map workers arbitrarily using Tags and other options. Cribl\u00c2 Stream refers to \u201cWorkers\u201d at several levels. Now that you\u2019ve been initiated into building distributed deployments, here\u2019s a guide to the fine points of distinguishing these levels: A Worker\u00c2 Group holds one or multiple Worker Nodes. Each Worker\u00c2 Node functions like an independent Cribl\u00c2 Stream single-instance deployment. Worker\u00c2 Nodes don\u2019t coordinate directly with each other \u00e2\u0080\u0093 they\u2019re coordinated only through communication to/from the Leader\u00c2 Node. Each Worker\u00c2 Node contains a configured number of Worker Processes. Unlike the above grouping abstractions, this is the level that actually processes data. To load-balance among Worker\u00c2 Processes, Cribl\u00c2 Stream\u2019s API\u00c2 Process round-robins incoming connections to them. When deploying on AWS/EKS, Worker Groups should not span Availability\u00c2 Zones. If you have EBS persistent volumes, and a node fails, its replacement won\u2019t be able to access the peer volume across AZs. If and when you choose to shut down the infrastructure you\u2019ve configured for this demonstration: Navigate to Cribl\u00c2 Stream\u2019s default Group\u00c2 > Data\u00c2 > Sources\u00c2 > Datagen, and switch off the toggle beside weblog.log. If you configured a second Worker Group: Navigate to Cribl\u00c2 Stream\u2019s CriblMetrics Group\u00c2 > Data\u00c2 > Sources\u00c2 > Cribl\u00c2 Internal, and disable the toggle beside CriblMetrics. If you have netcat running on a Worker\u2019s terminal/console, ^C it. There\u2019s no need (or way) to switch off the DevNull Destination \u00e2\u0080\u0093 it just is. If desired, Commit and Deploy these changes. If you\u2019re running the Cribl\u00c2 Stream server(s) on cloud instances that will (ultimately) incur charges, you\u2019re now free to shut down those cloud resources. Interested in guided walk-throughs of more-advanced Cribl\u00c2 Stream features? We suggest that you next check out these further resources. Distributed Deployment: All the details behind the deployment approach you just mastered in this tutorial. Cribl\u00c2 Stream Sandboxes: Work through general and specific scenarios in a free, hosted environment, with terminal access and real data inputs and outputs. Use Cases documentation: Bring your own services to build solutions to specific challenges. Cribl Concept: Pipelines \u00e2\u0080\u0093 Video showing how to build and use Pipelines at multiple Cribl\u00c2 Stream stages. Cribl Concept: Routing \u00e2\u0080\u0093 Video about using Routes to send different data through different paths.\""
    },
    {
        "question_answer": {
            "question": "What is the purpose of data cloning on the F5 load balancer?",
            "answer": "The purpose of data cloning on the F5 load balancer is to duplicate data to Cribl workers. This allows for routing, filtering, and reducing production data in Cribl without impacting production operations.",
            "follow_up_question_1": "How does data cloning on the F5 load balancer benefit the cutover to Cribl?",
            "follow_up_answer_1": "Data cloning on the F5 load balancer ensures that Cribl will be ready for the cutover without much impact. It allows for the gradual transition from syslog to Cribl while still being able to operate on all the data.",
            "follow_up_question_2": "Are there any issues with the cloned syslog data from the F5 not being seen by the Cribl worker?",
            "follow_up_answer_2": "Yes, there is a specific problem where the cloned syslog data from the F5 is not being picked up by Cribl. The data is making it to the correct interface and port on the worker, but Cribl is not recognizing it.",
            "follow_up_question_3": "Could the F5 be sending the cloned data in the wrong format?",
            "follow_up_answer_3": "It's possible that the F5 is sending the cloned data in a format that Cribl does not recognize. This could be causing the issue of Cribl not picking up the data.",
            "follow_up_question_4": "Is there any Linux configuration that could be causing the issue?",
            "follow_up_answer_4": "There could be a Linux configuration that is missing or incorrect, which is preventing Cribl from recognizing the cloned data. It would be worth checking the configuration to ensure everything is set up correctly.",
            "url": "https://community.cribl.io/discussion/777/data-cloned-on-f5-and-sent-to-cribl-workers"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/discussion/777/data-cloned-on-f5-and-sent-to-cribl-workers,Data cloned on F5 and sent to Cribl workers \u2014 Curious + Community,\"Posting this to get community feedback and track our progress in case anyone encounters this issue in the future. We are attempting to use the data cloning functionality on our F5 load balancer to duplicate data to our Cribl workers. We want to do this so that we can route, filter, and reduce production data in Cribl without impacting production operations. When the time comes, Cribl will be ready for the cutover without much impact at all, hopefully. Right now, the F5 is sending data to our syslog servers, which then send to Splunk. The end goal is to replace syslog with Cribl, but we want to be able to see all the data in Cribl before then so that we can operate on it. We are successfully cloning data that comes from Splunk UFs and HFs, but the cloned syslog data from the F5 is not being seen by the Cribl worker. The specific problem is this: The data is making it to the to the correct interface and port on the worker, but is not being picked up by Cribl for whatever reason. I have verified that data is coming in by using tcpdump to view the packets. We have turned off the local firewall on the server. There are no iptables rules dropping the traffic. I have verified \"\"net.ipv4.all.rp_filter\"\" is not present in sysctl. I'm not an F5 engineer, so I am mostly looking for feedback from that standpoint. Could the F5 be sending data in the wrong format, if that makes sense? My logic is that if the data is hitting the correct interface/port on the worker, then Cribl should be picking it up, but maybe that logic is flawed. Maybe there is a Linux configuration I am missing. Funny thing is, we can see the UDP port monitoring traffic that the F5 sends to the worker, but not the data that it is cloning and sending. \u00a9 Cribl 2023 | Legal | Code of Conduct\""
    },
    {
        "question_answer": {
            "question": "How does data cloning on the F5 load balancer work?",
            "answer": "Data cloning on the F5 load balancer involves duplicating data to Cribl workers. This allows for routing, filtering, and reducing production data in Cribl without impacting production operations.",
            "follow_up_question_1": "What is the benefit of duplicating data to Cribl workers?",
            "follow_up_answer_1": "Duplicating data to Cribl workers allows for the gradual transition from syslog to Cribl. It ensures that Cribl will be ready for the cutover without much impact and allows for operating on all the data.",
            "follow_up_question_2": "Are there any issues with the cloned syslog data from the F5 not being seen by the Cribl worker?",
            "follow_up_answer_2": "Yes, there is a specific problem where the cloned syslog data from the F5 is not being picked up by Cribl. The data is making it to the correct interface and port on the worker, but Cribl is not recognizing it.",
            "follow_up_question_3": "Could the F5 be sending the cloned data in the wrong format?",
            "follow_up_answer_3": "It's possible that the F5 is sending the cloned data in a format that Cribl does not recognize. This could be causing the issue of Cribl not picking up the data.",
            "follow_up_question_4": "Is there any Linux configuration that could be causing the issue?",
            "follow_up_answer_4": "There could be a Linux configuration that is missing or incorrect, which is preventing Cribl from recognizing the cloned data. It would be worth checking the configuration to ensure everything is set up correctly.",
            "url": "https://community.cribl.io/discussion/777/data-cloned-on-f5-and-sent-to-cribl-workers"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/discussion/777/data-cloned-on-f5-and-sent-to-cribl-workers,Data cloned on F5 and sent to Cribl workers \u2014 Curious + Community,\"Posting this to get community feedback and track our progress in case anyone encounters this issue in the future. We are attempting to use the data cloning functionality on our F5 load balancer to duplicate data to our Cribl workers. We want to do this so that we can route, filter, and reduce production data in Cribl without impacting production operations. When the time comes, Cribl will be ready for the cutover without much impact at all, hopefully. Right now, the F5 is sending data to our syslog servers, which then send to Splunk. The end goal is to replace syslog with Cribl, but we want to be able to see all the data in Cribl before then so that we can operate on it. We are successfully cloning data that comes from Splunk UFs and HFs, but the cloned syslog data from the F5 is not being seen by the Cribl worker. The specific problem is this: The data is making it to the to the correct interface and port on the worker, but is not being picked up by Cribl for whatever reason. I have verified that data is coming in by using tcpdump to view the packets. We have turned off the local firewall on the server. There are no iptables rules dropping the traffic. I have verified \"\"net.ipv4.all.rp_filter\"\" is not present in sysctl. I'm not an F5 engineer, so I am mostly looking for feedback from that standpoint. Could the F5 be sending data in the wrong format, if that makes sense? My logic is that if the data is hitting the correct interface/port on the worker, then Cribl should be picking it up, but maybe that logic is flawed. Maybe there is a Linux configuration I am missing. Funny thing is, we can see the UDP port monitoring traffic that the F5 sends to the worker, but not the data that it is cloning and sending. \u00a9 Cribl 2023 | Legal | Code of Conduct\""
    },
    {
        "question_answer": {
            "question": "What is the end goal of using data cloning on the F5 load balancer?",
            "answer": "The end goal of using data cloning on the F5 load balancer is to replace syslog with Cribl. The intention is to be able to see all the data in Cribl before the transition, so that operations can be performed on it.",
            "follow_up_question_1": "Why is it important to see all the data in Cribl before the transition?",
            "follow_up_answer_1": "Seeing all the data in Cribl before the transition allows for operations to be performed on it. It ensures that Cribl will be ready for the cutover without much impact and allows for a smooth transition from syslog to Cribl.",
            "follow_up_question_2": "Are there any issues with the cloned syslog data from the F5 not being seen by the Cribl worker?",
            "follow_up_answer_2": "Yes, there is a specific problem where the cloned syslog data from the F5 is not being picked up by Cribl. The data is making it to the correct interface and port on the worker, but Cribl is not recognizing it.",
            "follow_up_question_3": "Could the F5 be sending the cloned data in the wrong format?",
            "follow_up_answer_3": "It's possible that the F5 is sending the cloned data in a format that Cribl does not recognize. This could be causing the issue of Cribl not picking up the data.",
            "follow_up_question_4": "Is there any Linux configuration that could be causing the issue?",
            "follow_up_answer_4": "There could be a Linux configuration that is missing or incorrect, which is preventing Cribl from recognizing the cloned data. It would be worth checking the configuration to ensure everything is set up correctly.",
            "url": "https://community.cribl.io/discussion/777/data-cloned-on-f5-and-sent-to-cribl-workers"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/discussion/777/data-cloned-on-f5-and-sent-to-cribl-workers,Data cloned on F5 and sent to Cribl workers \u2014 Curious + Community,\"Posting this to get community feedback and track our progress in case anyone encounters this issue in the future. We are attempting to use the data cloning functionality on our F5 load balancer to duplicate data to our Cribl workers. We want to do this so that we can route, filter, and reduce production data in Cribl without impacting production operations. When the time comes, Cribl will be ready for the cutover without much impact at all, hopefully. Right now, the F5 is sending data to our syslog servers, which then send to Splunk. The end goal is to replace syslog with Cribl, but we want to be able to see all the data in Cribl before then so that we can operate on it. We are successfully cloning data that comes from Splunk UFs and HFs, but the cloned syslog data from the F5 is not being seen by the Cribl worker. The specific problem is this: The data is making it to the to the correct interface and port on the worker, but is not being picked up by Cribl for whatever reason. I have verified that data is coming in by using tcpdump to view the packets. We have turned off the local firewall on the server. There are no iptables rules dropping the traffic. I have verified \"\"net.ipv4.all.rp_filter\"\" is not present in sysctl. I'm not an F5 engineer, so I am mostly looking for feedback from that standpoint. Could the F5 be sending data in the wrong format, if that makes sense? My logic is that if the data is hitting the correct interface/port on the worker, then Cribl should be picking it up, but maybe that logic is flawed. Maybe there is a Linux configuration I am missing. Funny thing is, we can see the UDP port monitoring traffic that the F5 sends to the worker, but not the data that it is cloning and sending. \u00a9 Cribl 2023 | Legal | Code of Conduct\""
    },
    {
        "question_answer": {
            "question": "What is the specific problem with the cloned syslog data from the F5 not being seen by the Cribl worker?",
            "answer": "The specific problem is that the cloned syslog data from the F5 is not being picked up by Cribl. The data is making it to the correct interface and port on the worker, but Cribl is not recognizing it.",
            "follow_up_question_1": "Could the F5 be sending the cloned data in the wrong format?",
            "follow_up_answer_1": "It's possible that the F5 is sending the cloned data in a format that Cribl does not recognize. This could be causing the issue of Cribl not picking up the data.",
            "follow_up_question_2": "Is there any Linux configuration that could be causing the issue?",
            "follow_up_answer_2": "There could be a Linux configuration that is missing or incorrect, which is preventing Cribl from recognizing the cloned data. It would be worth checking the configuration to ensure everything is set up correctly.",
            "follow_up_question_3": "What steps have been taken to troubleshoot the issue?",
            "follow_up_answer_3": "So far, the steps taken include verifying that data is coming in by using tcpdump to view the packets, turning off the local firewall on the server, and checking for any iptables rules dropping the traffic. However, the issue still persists.",
            "url": "https://community.cribl.io/discussion/777/data-cloned-on-f5-and-sent-to-cribl-workers"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/discussion/777/data-cloned-on-f5-and-sent-to-cribl-workers,Data cloned on F5 and sent to Cribl workers \u2014 Curious + Community,\"Posting this to get community feedback and track our progress in case anyone encounters this issue in the future. We are attempting to use the data cloning functionality on our F5 load balancer to duplicate data to our Cribl workers. We want to do this so that we can route, filter, and reduce production data in Cribl without impacting production operations. When the time comes, Cribl will be ready for the cutover without much impact at all, hopefully. Right now, the F5 is sending data to our syslog servers, which then send to Splunk. The end goal is to replace syslog with Cribl, but we want to be able to see all the data in Cribl before then so that we can operate on it. We are successfully cloning data that comes from Splunk UFs and HFs, but the cloned syslog data from the F5 is not being seen by the Cribl worker. The specific problem is this: The data is making it to the to the correct interface and port on the worker, but is not being picked up by Cribl for whatever reason. I have verified that data is coming in by using tcpdump to view the packets. We have turned off the local firewall on the server. There are no iptables rules dropping the traffic. I have verified \"\"net.ipv4.all.rp_filter\"\" is not present in sysctl. I'm not an F5 engineer, so I am mostly looking for feedback from that standpoint. Could the F5 be sending data in the wrong format, if that makes sense? My logic is that if the data is hitting the correct interface/port on the worker, then Cribl should be picking it up, but maybe that logic is flawed. Maybe there is a Linux configuration I am missing. Funny thing is, we can see the UDP port monitoring traffic that the F5 sends to the worker, but not the data that it is cloning and sending. \u00a9 Cribl 2023 | Legal | Code of Conduct\""
    },
    {
        "question_answer": {
            "question": "Is there any Linux configuration that could be causing the issue of the cloned syslog data not being seen by the Cribl worker?",
            "answer": "There could be a Linux configuration that is missing or incorrect, which is preventing Cribl from recognizing the cloned syslog data. It would be worth checking the configuration to ensure everything is set up correctly.",
            "follow_up_question_1": "What specific Linux configuration should be checked?",
            "follow_up_answer_1": "The specific Linux configuration that should be checked includes verifying that the 'net.ipv4.all.rp_filter' is not present in sysctl. This configuration could potentially affect the recognition of the cloned syslog data by Cribl.",
            "follow_up_question_2": "What steps have been taken to troubleshoot the issue?",
            "follow_up_answer_2": "So far, the steps taken include verifying that data is coming in by using tcpdump to view the packets, turning off the local firewall on the server, and checking for any iptables rules dropping the traffic. However, the issue still persists.",
            "url": "https://community.cribl.io/discussion/777/data-cloned-on-f5-and-sent-to-cribl-workers"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/discussion/777/data-cloned-on-f5-and-sent-to-cribl-workers,Data cloned on F5 and sent to Cribl workers \u2014 Curious + Community,\"Posting this to get community feedback and track our progress in case anyone encounters this issue in the future. We are attempting to use the data cloning functionality on our F5 load balancer to duplicate data to our Cribl workers. We want to do this so that we can route, filter, and reduce production data in Cribl without impacting production operations. When the time comes, Cribl will be ready for the cutover without much impact at all, hopefully. Right now, the F5 is sending data to our syslog servers, which then send to Splunk. The end goal is to replace syslog with Cribl, but we want to be able to see all the data in Cribl before then so that we can operate on it. We are successfully cloning data that comes from Splunk UFs and HFs, but the cloned syslog data from the F5 is not being seen by the Cribl worker. The specific problem is this: The data is making it to the to the correct interface and port on the worker, but is not being picked up by Cribl for whatever reason. I have verified that data is coming in by using tcpdump to view the packets. We have turned off the local firewall on the server. There are no iptables rules dropping the traffic. I have verified \"\"net.ipv4.all.rp_filter\"\" is not present in sysctl. I'm not an F5 engineer, so I am mostly looking for feedback from that standpoint. Could the F5 be sending data in the wrong format, if that makes sense? My logic is that if the data is hitting the correct interface/port on the worker, then Cribl should be picking it up, but maybe that logic is flawed. Maybe there is a Linux configuration I am missing. Funny thing is, we can see the UDP port monitoring traffic that the F5 sends to the worker, but not the data that it is cloning and sending. \u00a9 Cribl 2023 | Legal | Code of Conduct\""
    },
    {
        "question_answer": {
            "question": "What is Cribl?",
            "answer": "Cribl is a community platform that allows users to connect and engage with other members who are curious and interested in various topics.",
            "follow_up_question_1": "How can I join the Cribl community?",
            "follow_up_answer_1": "To join the Cribl community, you can visit the Cribl website and create an account. Once you have an account, you can start exploring and participating in the community discussions.",
            "follow_up_question_2": "What are the benefits of joining the Cribl community?",
            "follow_up_answer_2": "By joining the Cribl community, you can connect with like-minded individuals, share your knowledge and experiences, learn from others, and stay updated on the latest trends and developments in your areas of interest.",
            "follow_up_question_3": "Are there any specific rules or guidelines for participating in the Cribl community?",
            "follow_up_answer_3": "Yes, Cribl has a Code of Conduct that all members are expected to follow. It promotes respectful and inclusive communication, prohibits spamming and trolling, and encourages constructive discussions. You can find the Code of Conduct on the Cribl website.",
            "url": "https://community.cribl.io/profile/Hillary%20Masciave"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/profile/Hillary%20Masciave,Hillary Masciave \u2014 Curious + Community,\u00a9 Cribl 2023 | Legal | Code of Conduct"
    },
    {
        "question_answer": {
            "question": "What topics are discussed in the Cribl community?",
            "answer": "The Cribl community covers a wide range of topics, including technology, data management, analytics, and more.",
            "follow_up_question_1": "Can you give me some examples of specific topics discussed in the community?",
            "follow_up_answer_1": "Sure! Some examples of topics discussed in the Cribl community include log management, data routing, observability, and data transformation.",
            "follow_up_question_2": "Are there any experts or industry professionals who participate in the community discussions?",
            "follow_up_answer_2": "Yes, the Cribl community attracts experts and industry professionals who are passionate about the topics being discussed. Their insights and experiences add value to the discussions and provide valuable learning opportunities for other members.",
            "follow_up_question_3": "How can I start a discussion on a specific topic in the Cribl community?",
            "follow_up_answer_3": "To start a discussion on a specific topic, you can create a new post in the relevant category or join an existing discussion by commenting on a post. Make sure to provide clear and concise information to encourage meaningful engagement from other community members.",
            "url": "https://community.cribl.io/profile/Hillary%20Masciave"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/profile/Hillary%20Masciave,Hillary Masciave \u2014 Curious + Community,\u00a9 Cribl 2023 | Legal | Code of Conduct"
    },
    {
        "question_answer": {
            "question": "Is the Cribl community open to beginners or is it more focused on advanced users?",
            "answer": "The Cribl community welcomes users of all levels, from beginners to advanced users. It is a place for learning, sharing, and collaboration.",
            "follow_up_question_1": "Are there any resources or tutorials available for beginners in the Cribl community?",
            "follow_up_answer_1": "Yes, the Cribl community provides resources and tutorials specifically designed for beginners. These resources can help newcomers get started and gain a better understanding of the topics being discussed.",
            "follow_up_question_2": "How can advanced users benefit from participating in the Cribl community?",
            "follow_up_answer_2": "Advanced users can benefit from participating in the Cribl community by sharing their expertise, mentoring beginners, and engaging in discussions with other experienced professionals. It's a great opportunity to expand their knowledge and stay updated on industry trends.",
            "follow_up_question_3": "Are there any networking opportunities available in the Cribl community?",
            "follow_up_answer_3": "Yes, the Cribl community provides networking opportunities through various channels, such as online events, webinars, and virtual meetups. These events allow members to connect with each other, exchange ideas, and build professional relationships.",
            "url": "https://community.cribl.io/profile/Hillary%20Masciave"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/profile/Hillary%20Masciave,Hillary Masciave \u2014 Curious + Community,\u00a9 Cribl 2023 | Legal | Code of Conduct"
    },
    {
        "question_answer": {
            "question": "How can I contribute to the Cribl community?",
            "answer": "There are several ways to contribute to the Cribl community. You can share your knowledge and experiences by participating in discussions, writing blog posts, creating tutorials, or even organizing community events.",
            "follow_up_question_1": "Are there any guidelines for creating blog posts or tutorials for the Cribl community?",
            "follow_up_answer_1": "Yes, the Cribl community has guidelines for creating blog posts and tutorials. These guidelines ensure that the content is informative, well-structured, and relevant to the community's interests. You can find the guidelines on the Cribl website.",
            "follow_up_question_2": "Can I organize my own community event in the Cribl community?",
            "follow_up_answer_2": "Yes, you can organize your own community event in the Cribl community. Whether it's a webinar, workshop, or virtual meetup, you have the opportunity to share your expertise and connect with other members who are interested in the topic you're passionate about.",
            "follow_up_question_3": "How can I get recognition for my contributions to the Cribl community?",
            "follow_up_answer_3": "Cribl recognizes and appreciates the contributions of its community members. You can earn badges, receive mentions in the community newsletter, and even be invited to become a community ambassador or moderator based on your active participation and valuable contributions.",
            "url": "https://community.cribl.io/profile/Hillary%20Masciave"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/profile/Hillary%20Masciave,Hillary Masciave \u2014 Curious + Community,\u00a9 Cribl 2023 | Legal | Code of Conduct"
    },
    {
        "question_answer": {
            "question": "What is Cribl.Cloud?",
            "answer": "Cribl.Cloud is a platform that allows you to manage and analyze your log data in a centralized and efficient way.",
            "follow_up_question_1": "How does Cribl.Cloud help with log data management?",
            "follow_up_answer_1": "Cribl.Cloud provides features like log routing, filtering, and transformation, which allow you to control how your log data is processed and sent to different destinations. It helps you reduce data volume, improve data quality, and ensure that your log data is delivered to the right tools and systems.",
            "follow_up_question_2": "Can you give me an example of how log routing works in Cribl.Cloud?",
            "follow_up_answer_2": "Certainly! Let's say you have log data coming from multiple sources, such as applications, servers, and network devices. With Cribl.Cloud, you can create routing rules based on different criteria like log content, source IP, or timestamp. These rules determine where each log event should be sent, whether it's to a specific destination, a group of destinations, or even to different destinations based on the log content.",
            "follow_up_question_3": "What are some benefits of using log filtering in Cribl.Cloud?",
            "follow_up_answer_3": "Log filtering in Cribl.Cloud allows you to remove unnecessary log events or fields that are not relevant to your analysis. This helps reduce data volume and improves the efficiency of downstream systems. You can filter logs based on various conditions like log content, source, or specific fields. It helps you focus on the data that matters most to your analysis and reduces noise in your log data.",
            "url": "https://cribl.io/cribl-cloud/try-cribl-cloud/"
        },
        "reference": "url,title,text_chunks https://cribl.io/cribl-cloud/try-cribl-cloud/,Free Cribl.Cloud Trial - Cribl,\"Check out the success story > Check out the success story > Nothing to install, no infrastructure to manage, no license required, no payment collected.\""
    },
    {
        "question_answer": {
            "question": "How can I try Cribl.Cloud?",
            "answer": "You can try Cribl.Cloud for free without any installation or infrastructure management.",
            "follow_up_question_1": "Is there a trial period for Cribl.Cloud?",
            "follow_up_answer_1": "Yes, there is a free trial period available for Cribl.Cloud. During the trial, you can explore and test out the features and capabilities of the platform.",
            "follow_up_question_2": "Do I need to provide any payment information to start the free trial?",
            "follow_up_answer_2": "No, you don't need to provide any payment information to start the free trial. It's completely free and no payment will be collected during the trial period.",
            "follow_up_question_3": "What are the requirements to try Cribl.Cloud?",
            "follow_up_answer_3": "There are no specific requirements to try Cribl.Cloud. Since it is a cloud-based platform, you don't need to install any software or manage any infrastructure. You can simply sign up for the trial and start using it.",
            "url": "https://cribl.io/cribl-cloud/try-cribl-cloud/"
        },
        "reference": "url,title,text_chunks https://cribl.io/cribl-cloud/try-cribl-cloud/,Free Cribl.Cloud Trial - Cribl,\"Check out the success story > Check out the success story > Nothing to install, no infrastructure to manage, no license required, no payment collected.\""
    },
    {
        "question_answer": {
            "question": "What are the key features of Cribl.Cloud?",
            "answer": "Cribl.Cloud offers features like log routing, filtering, transformation, and integration with various destinations.",
            "follow_up_question_1": "Can you explain the log transformation feature in Cribl.Cloud?",
            "follow_up_answer_1": "Log transformation in Cribl.Cloud allows you to modify the structure or content of your log data before sending it to the destination. You can extract specific fields, enrich the data with additional information, or even anonymize sensitive data. It gives you the flexibility to customize your log data based on your specific requirements.",
            "follow_up_question_2": "What destinations can I integrate with Cribl.Cloud?",
            "follow_up_answer_2": "Cribl.Cloud supports integration with various destinations, including popular log management and analytics platforms like Splunk, Elasticsearch, and Datadog. You can easily configure the destinations and route your log data to these platforms for further analysis and monitoring.",
            "follow_up_question_3": "How does Cribl.Cloud ensure the security of log data?",
            "follow_up_answer_3": "Cribl.Cloud takes security seriously and provides features like data encryption, access controls, and audit logs to ensure the confidentiality, integrity, and availability of your log data. It also supports integration with identity providers for user authentication and authorization.",
            "url": "https://cribl.io/cribl-cloud/try-cribl-cloud/"
        },
        "reference": "url,title,text_chunks https://cribl.io/cribl-cloud/try-cribl-cloud/,Free Cribl.Cloud Trial - Cribl,\"Check out the success story > Check out the success story > Nothing to install, no infrastructure to manage, no license required, no payment collected.\""
    },
    {
        "question_answer": {
            "question": "What is Stream and how does it differ from logstash?",
            "answer": "Stream is a product offered by Cribl that provides routing and transforming capabilities for data. While logstash also performs similar functions, Stream offers several advantages. It provides an out-of-the-box solution for building configurations, which can save time and effort compared to manually configuring logstash. Additionally, Stream offers reduction use cases such as suppressing, sampling, dropping, and logging to metrics. It also allows for replaying historical data and enriching data with lookup. Another benefit of Stream is its ability to reshape data for Elastic SIEM.",
            "follow_up_question_1": "Can you explain how Stream's out-of-the-box solution for building configurations works?",
            "follow_up_answer_1": "Certainly! Stream provides pre-built configurations that can be easily customized to fit specific data routing and transforming needs. These configurations are designed to be user-friendly and intuitive, allowing users to quickly set up their data pipelines without the need for extensive manual configuration.",
            "follow_up_question_2": "How does Stream handle reduction use cases like suppressing, sampling, dropping, and logging to metrics?",
            "follow_up_answer_2": "Stream offers built-in functionalities for handling these reduction use cases. Users can easily configure Stream to suppress or drop certain types of data based on specified criteria. Sampling allows users to select a subset of data for further analysis. Additionally, Stream provides the ability to log data to metrics, allowing users to track and monitor data flow and performance.",
            "follow_up_question_3": "Can you provide an example of how Stream can be used to enrich data with lookup?",
            "follow_up_answer_3": "Certainly! Let's say you have a dataset that contains customer IDs, and you want to enrich this data with additional information such as customer names and addresses. With Stream, you can configure a lookup operation that references an external data source, such as a customer database. Stream will then automatically retrieve the relevant information based on the customer IDs in the dataset and add it to the output data.",
            "follow_up_question_4": "How does Stream reshape data for Elastic SIEM?",
            "follow_up_answer_4": "Stream provides powerful transformation capabilities that allow users to reshape data to fit the requirements of Elastic SIEM. Users can easily manipulate the structure and format of the data, ensuring that it is compatible with Elastic SIEM's data ingestion and analysis processes. This flexibility enables seamless integration between Stream and Elastic SIEM, enhancing the overall effectiveness of the SIEM solution.",
            "url": "https://community.cribl.io/discussion/782/what-value-would-stream-provide-to-someone-who-has-logstash-for-routing-transforming"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/discussion/782/what-value-would-stream-provide-to-someone-who-has-logstash-for-routing-transforming,What value would Stream provide to someone who has logstash for routing/transforming? \u2014 Curious + Community,\"So, this question has been bothering me for quite some time now. While I am a big fan of Cribl and I really enjoy working with their products and showing/explaining them to others I still wonder every now and then what value Stream would provide to a customer, who already has a well-maintained and functioning logstash for routing/transforming data. If I think about it the following points come to my mind, but if someone here has more/different reasons I would be glad to hear them! Overall, I would go after these use cases: Build configurations manually (logstash) vs out of the box solution (Cribl) Reduction use cases (Suppress, Sample, Drop, log to metrics) Replay historical data Enrich with Lookup Reshape for Elastic SIEM https://www.elastic.co/blog/elastic-cribl-migrate-siem https://cribl.io/customers/sally-beauty/ https://cribl.io/blog/cribl-logstream-7x-more-efficient-than-logstash-and-fluentd/ Overall, I would go after these use cases: Build configurations manually (logstash) vs out of the box solution (Cribl) Reduction use cases (Suppress, Sample, Drop, log to metrics) Replay historical data Enrich with Lookup Reshape for Elastic SIEM https://www.elastic.co/blog/elastic-cribl-migrate-siem https://cribl.io/customers/sally-beauty/ https://cribl.io/blog/cribl-logstream-7x-more-efficient-than-logstash-and-fluentd/ \u00a9 Cribl 2023 | Legal | Code of Conduct\""
    },
    {
        "question_answer": {
            "question": "What are the benefits of using Stream for someone who already has a well-maintained and functioning logstash?",
            "answer": "While logstash is a reliable tool for routing and transforming data, Stream offers several benefits that can enhance the existing data pipeline. One advantage is the out-of-the-box solution provided by Stream, which simplifies the configuration process and saves time. Additionally, Stream offers reduction use cases such as suppressing, sampling, dropping, and logging to metrics, which can help optimize data processing. Stream also allows for the replay of historical data, enabling users to analyze past events. Another benefit is the ability to enrich data with lookup, which can enhance the context and value of the data. Lastly, Stream provides data reshaping capabilities specifically designed for Elastic SIEM, ensuring seamless integration and compatibility.",
            "follow_up_question_1": "How does Stream simplify the configuration process compared to logstash?",
            "follow_up_answer_1": "Stream provides pre-built configurations that can be easily customized, eliminating the need for extensive manual configuration. This saves time and effort, especially for users who are already familiar with logstash and its configuration process. Additionally, Stream's user-friendly interface and intuitive design make it easier to set up and manage data pipelines.",
            "follow_up_question_2": "Can you explain how Stream's reduction use cases can optimize data processing?",
            "follow_up_answer_2": "Stream offers functionalities such as suppressing, sampling, dropping, and logging to metrics, which allow users to filter and prioritize data based on specific criteria. By reducing the amount of unnecessary or less relevant data, Stream helps optimize data processing and improves overall efficiency. This can result in faster data analysis and more accurate insights.",
            "follow_up_question_3": "How can the replay of historical data be beneficial for users?",
            "follow_up_answer_3": "The ability to replay historical data allows users to analyze past events and gain insights that may have been missed initially. This can be particularly useful for troubleshooting, identifying patterns or trends, and conducting retrospective analysis. By replaying historical data, users can ensure that their data pipeline is robust and capable of handling various scenarios.",
            "follow_up_question_4": "In what ways can data enrichment with lookup enhance the value of existing data?",
            "follow_up_answer_4": "Data enrichment with lookup allows users to add additional information or context to their existing data. This can include enriching customer data with demographic information, enriching log data with geolocation data, or enriching transaction data with product details. By enhancing the context and value of the data, users can gain deeper insights and make more informed decisions.",
            "follow_up_question_5": "How does Stream ensure seamless integration and compatibility with Elastic SIEM?",
            "follow_up_answer_5": "Stream provides specific data reshaping capabilities that are designed to align with the requirements of Elastic SIEM. This ensures that the data processed by Stream is compatible with Elastic SIEM's data ingestion and analysis processes. By seamlessly integrating with Elastic SIEM, Stream enhances the overall effectiveness of the SIEM solution and enables users to leverage the full capabilities of both tools.",
            "url": "https://community.cribl.io/discussion/782/what-value-would-stream-provide-to-someone-who-has-logstash-for-routing-transforming"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/discussion/782/what-value-would-stream-provide-to-someone-who-has-logstash-for-routing-transforming,What value would Stream provide to someone who has logstash for routing/transforming? \u2014 Curious + Community,\"So, this question has been bothering me for quite some time now. While I am a big fan of Cribl and I really enjoy working with their products and showing/explaining them to others I still wonder every now and then what value Stream would provide to a customer, who already has a well-maintained and functioning logstash for routing/transforming data. If I think about it the following points come to my mind, but if someone here has more/different reasons I would be glad to hear them! Overall, I would go after these use cases: Build configurations manually (logstash) vs out of the box solution (Cribl) Reduction use cases (Suppress, Sample, Drop, log to metrics) Replay historical data Enrich with Lookup Reshape for Elastic SIEM https://www.elastic.co/blog/elastic-cribl-migrate-siem https://cribl.io/customers/sally-beauty/ https://cribl.io/blog/cribl-logstream-7x-more-efficient-than-logstash-and-fluentd/ Overall, I would go after these use cases: Build configurations manually (logstash) vs out of the box solution (Cribl) Reduction use cases (Suppress, Sample, Drop, log to metrics) Replay historical data Enrich with Lookup Reshape for Elastic SIEM https://www.elastic.co/blog/elastic-cribl-migrate-siem https://cribl.io/customers/sally-beauty/ https://cribl.io/blog/cribl-logstream-7x-more-efficient-than-logstash-and-fluentd/ \u00a9 Cribl 2023 | Legal | Code of Conduct\""
    },
    {
        "question_answer": {
            "question": "What is observability?",
            "answer": "Observability is the ability to understand and analyze the internal state of a system based on its external outputs. It involves collecting and analyzing data from various sources to gain insights into the performance, behavior, and health of a system.",
            "follow_up_question_1": "How is observability different from monitoring?",
            "follow_up_answer_1": "While monitoring focuses on collecting and analyzing predefined metrics and alerts, observability goes beyond that by allowing you to explore and understand the system in a more dynamic and flexible way. It provides a holistic view of the system's behavior and helps identify and troubleshoot issues more effectively.",
            "follow_up_question_2": "What are the benefits of observability?",
            "follow_up_answer_2": "Observability helps improve system reliability, reduce downtime, and enhance troubleshooting capabilities. It enables proactive identification of issues, faster root cause analysis, and better decision-making based on real-time insights.",
            "follow_up_question_3": "How can observability be achieved?",
            "follow_up_answer_3": "Observability can be achieved by implementing a comprehensive observability pipeline that collects data from various sources, normalizes and enriches it, and makes it easily accessible for analysis. Tools like Cribl Stream and Cribl Edge can help in building such pipelines.",
            "url": "https://cribl.io/cribl-community-code-of-conduct/"
        },
        "reference": "url,title,text_chunks https://cribl.io/cribl-community-code-of-conduct/,Cribl Community Code of Conduct - Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. This community is dedicated to providing a harassment-free experience for everyone. We do not tolerate harassment of participants in any form. All participants in the Cribl User Community are subject to these rules. These rules are enforced by Cribl employees/administrators, aka the Cribl team. (Cribl employees include the word \u201ccribl\u201d in their usernames so you can identify them.) Applicability and scope This code of conduct applies to all Cribl Community spaces and public channels, private channels, and direct messages, both online and off, as well as all Cribl-sponsored in-person events, including user group events and user conferences. When you register for any Cribl-sponsored event, you agree to comply with all rules and requirements provided by venues hosting Cribl-sponsored in-person events. Anyone who violates this code of conduct may be sanctioned or expelled from these spaces at the discretion of the Cribl team. Creating a welcoming and safe environment We hope to create an environment in which diverse individuals can collaborate and interact in a positive and affirming way. Examples of behavior that contributes to creating this sort of environment include: What we mean when we say \u201charassment\u201d The Cribl community will not tolerate harassment of any kind. Examples of harassment include: If you have questions or concerns about these rules, message a Cribl employee or email community@cribl.io. How to report an issue If you are being harassed by a member of our community, notice that someone else is being harassed, or have any other concerns, please notify a Cribl employee via Direct Message. Note: If the person who is harassing you is a Cribl employee, they will not be involved in handling or resolving the incident. The Cribl team will respond to any complaint as promptly as we can. If you do not get a timely response (for example, if no Cribl employees are currently online) then please put your personal safety and well-being first, and consider logging out and/or contacting us by email at community@cribl.io. This code of conduct applies to our community\u2019s spaces, but if you are being harassed by a member of our community outside our spaces, we still want to know about it. We will take all good-faith reports of harassment by our members seriously. This includes harassment outside our spaces and harassment that took place at any point in time. The Cribl team reserves the right to exclude people from the Cribl community based on their past behavior, including behavior outside of our spaces and behavior towards people who are not in this community. In order to protect admins from abuse and burnout, we reserve the right to reject any report we believe to have been made in bad faith. Reports intended to silence legitimate criticism may be deleted or ignored without response. How we will enforce these rules Every code of conduct violation report will be treated with seriousness and care. If a member\u2019s immediate safety and security is threatened, an individual Cribl employee may take any action that they deem appropriate, up to and including temporarily banning the offender from the Cribl community. In less immediate situations, at least two Cribl employees will discuss the offense and mutually arrive at a suitable response, which will be shared with the offender privately. Whatever the resolution that they decide upon, which may include permanent expulsion of the community member, the decision of the Cribl employees involved in a violation case will be considered final. We will respect confidentiality requests for the purpose of protecting victims of abuse. At our discretion, we may publicly name a person about whom we\u2019ve received harassment complaints, or privately warn third parties about them, if we believe that doing so will increase the safety of our members or the general public. We will not name harassment victims without their affirmative consent. Consequences Participants asked to stop any harassing behavior are expected to comply immediately. If a participant engages in harassing behavior, we may take any action they deem appropriate, up to and including permanent expulsion from the Cribl community and identification of the participant as a harasser to other members. At the discretion of the Cribl team or by request, one or more of the parties involved may request to discuss the violation and how to avoid similar situations in the future. Acknowledgements This Code of Conduct is adapted from the Community Covenant ( http://community-covenant.net ) version 1.0, available at http://community-covenant.net/version/1/0/ . The Community Covenant is an open source effort and is built on codes of conduct that came before it, including the Contributor Covenant (http://contributor-covenant.org/) and the LGBTQ in Tech community code of conduct ( http://lgbtq.technology/coc.html ). License Community Covenant by Coraline Ada Ehmke is licensed under a Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/). Based on a work at http://community-covenant.net/. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    },
    {
        "question_answer": {
            "question": "What is Cribl Stream?",
            "answer": "Cribl Stream is a vendor-agnostic observability pipeline that allows you to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure.",
            "follow_up_question_1": "How does Cribl Stream help in observability?",
            "follow_up_answer_1": "Cribl Stream helps in observability by providing a flexible and scalable solution for collecting and processing data. It allows you to easily ingest data from various sources, apply transformations and enrichments, and route it to the desired destinations for analysis.",
            "follow_up_question_2": "Can Cribl Stream handle large volumes of data?",
            "follow_up_answer_2": "Yes, Cribl Stream is designed to handle high volumes of data. It is highly scalable and can process data in real-time, ensuring that you can collect and analyze data at any scale.",
            "follow_up_question_3": "What are some use cases for Cribl Stream?",
            "follow_up_answer_3": "Cribl Stream can be used for various observability use cases, such as log management, metrics collection, and application data processing. It provides a flexible and customizable solution that can be tailored to meet specific requirements.",
            "url": "https://cribl.io/cribl-community-code-of-conduct/"
        },
        "reference": "url,title,text_chunks https://cribl.io/cribl-community-code-of-conduct/,Cribl Community Code of Conduct - Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. This community is dedicated to providing a harassment-free experience for everyone. We do not tolerate harassment of participants in any form. All participants in the Cribl User Community are subject to these rules. These rules are enforced by Cribl employees/administrators, aka the Cribl team. (Cribl employees include the word \u201ccribl\u201d in their usernames so you can identify them.) Applicability and scope This code of conduct applies to all Cribl Community spaces and public channels, private channels, and direct messages, both online and off, as well as all Cribl-sponsored in-person events, including user group events and user conferences. When you register for any Cribl-sponsored event, you agree to comply with all rules and requirements provided by venues hosting Cribl-sponsored in-person events. Anyone who violates this code of conduct may be sanctioned or expelled from these spaces at the discretion of the Cribl team. Creating a welcoming and safe environment We hope to create an environment in which diverse individuals can collaborate and interact in a positive and affirming way. Examples of behavior that contributes to creating this sort of environment include: What we mean when we say \u201charassment\u201d The Cribl community will not tolerate harassment of any kind. Examples of harassment include: If you have questions or concerns about these rules, message a Cribl employee or email community@cribl.io. How to report an issue If you are being harassed by a member of our community, notice that someone else is being harassed, or have any other concerns, please notify a Cribl employee via Direct Message. Note: If the person who is harassing you is a Cribl employee, they will not be involved in handling or resolving the incident. The Cribl team will respond to any complaint as promptly as we can. If you do not get a timely response (for example, if no Cribl employees are currently online) then please put your personal safety and well-being first, and consider logging out and/or contacting us by email at community@cribl.io. This code of conduct applies to our community\u2019s spaces, but if you are being harassed by a member of our community outside our spaces, we still want to know about it. We will take all good-faith reports of harassment by our members seriously. This includes harassment outside our spaces and harassment that took place at any point in time. The Cribl team reserves the right to exclude people from the Cribl community based on their past behavior, including behavior outside of our spaces and behavior towards people who are not in this community. In order to protect admins from abuse and burnout, we reserve the right to reject any report we believe to have been made in bad faith. Reports intended to silence legitimate criticism may be deleted or ignored without response. How we will enforce these rules Every code of conduct violation report will be treated with seriousness and care. If a member\u2019s immediate safety and security is threatened, an individual Cribl employee may take any action that they deem appropriate, up to and including temporarily banning the offender from the Cribl community. In less immediate situations, at least two Cribl employees will discuss the offense and mutually arrive at a suitable response, which will be shared with the offender privately. Whatever the resolution that they decide upon, which may include permanent expulsion of the community member, the decision of the Cribl employees involved in a violation case will be considered final. We will respect confidentiality requests for the purpose of protecting victims of abuse. At our discretion, we may publicly name a person about whom we\u2019ve received harassment complaints, or privately warn third parties about them, if we believe that doing so will increase the safety of our members or the general public. We will not name harassment victims without their affirmative consent. Consequences Participants asked to stop any harassing behavior are expected to comply immediately. If a participant engages in harassing behavior, we may take any action they deem appropriate, up to and including permanent expulsion from the Cribl community and identification of the participant as a harasser to other members. At the discretion of the Cribl team or by request, one or more of the parties involved may request to discuss the violation and how to avoid similar situations in the future. Acknowledgements This Code of Conduct is adapted from the Community Covenant ( http://community-covenant.net ) version 1.0, available at http://community-covenant.net/version/1/0/ . The Community Covenant is an open source effort and is built on codes of conduct that came before it, including the Contributor Covenant (http://contributor-covenant.org/) and the LGBTQ in Tech community code of conduct ( http://lgbtq.technology/coc.html ). License Community Covenant by Coraline Ada Ehmke is licensed under a Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/). Based on a work at http://community-covenant.net/. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    },
    {
        "question_answer": {
            "question": "What is Cribl Edge?",
            "answer": "Cribl Edge is an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data.",
            "follow_up_question_1": "How does Cribl Edge work?",
            "follow_up_answer_1": "Cribl Edge works by deploying lightweight agents at the edge of your network or infrastructure. These agents collect and process data locally, reducing the volume of data that needs to be sent to centralized systems. This helps in optimizing network bandwidth and reducing latency.",
            "follow_up_question_2": "What are the benefits of using Cribl Edge?",
            "follow_up_answer_2": "Using Cribl Edge can help in reducing the load on centralized systems, improving data processing efficiency, and enhancing overall observability capabilities. It allows you to collect and process data closer to its source, enabling faster analysis and response times.",
            "follow_up_question_3": "Can Cribl Edge handle data from different sources?",
            "follow_up_answer_3": "Yes, Cribl Edge is designed to handle data from various sources, including logs, metrics, and application data. It provides a unified platform for collecting and processing data from different systems and applications.",
            "url": "https://cribl.io/cribl-community-code-of-conduct/"
        },
        "reference": "url,title,text_chunks https://cribl.io/cribl-community-code-of-conduct/,Cribl Community Code of Conduct - Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. This community is dedicated to providing a harassment-free experience for everyone. We do not tolerate harassment of participants in any form. All participants in the Cribl User Community are subject to these rules. These rules are enforced by Cribl employees/administrators, aka the Cribl team. (Cribl employees include the word \u201ccribl\u201d in their usernames so you can identify them.) Applicability and scope This code of conduct applies to all Cribl Community spaces and public channels, private channels, and direct messages, both online and off, as well as all Cribl-sponsored in-person events, including user group events and user conferences. When you register for any Cribl-sponsored event, you agree to comply with all rules and requirements provided by venues hosting Cribl-sponsored in-person events. Anyone who violates this code of conduct may be sanctioned or expelled from these spaces at the discretion of the Cribl team. Creating a welcoming and safe environment We hope to create an environment in which diverse individuals can collaborate and interact in a positive and affirming way. Examples of behavior that contributes to creating this sort of environment include: What we mean when we say \u201charassment\u201d The Cribl community will not tolerate harassment of any kind. Examples of harassment include: If you have questions or concerns about these rules, message a Cribl employee or email community@cribl.io. How to report an issue If you are being harassed by a member of our community, notice that someone else is being harassed, or have any other concerns, please notify a Cribl employee via Direct Message. Note: If the person who is harassing you is a Cribl employee, they will not be involved in handling or resolving the incident. The Cribl team will respond to any complaint as promptly as we can. If you do not get a timely response (for example, if no Cribl employees are currently online) then please put your personal safety and well-being first, and consider logging out and/or contacting us by email at community@cribl.io. This code of conduct applies to our community\u2019s spaces, but if you are being harassed by a member of our community outside our spaces, we still want to know about it. We will take all good-faith reports of harassment by our members seriously. This includes harassment outside our spaces and harassment that took place at any point in time. The Cribl team reserves the right to exclude people from the Cribl community based on their past behavior, including behavior outside of our spaces and behavior towards people who are not in this community. In order to protect admins from abuse and burnout, we reserve the right to reject any report we believe to have been made in bad faith. Reports intended to silence legitimate criticism may be deleted or ignored without response. How we will enforce these rules Every code of conduct violation report will be treated with seriousness and care. If a member\u2019s immediate safety and security is threatened, an individual Cribl employee may take any action that they deem appropriate, up to and including temporarily banning the offender from the Cribl community. In less immediate situations, at least two Cribl employees will discuss the offense and mutually arrive at a suitable response, which will be shared with the offender privately. Whatever the resolution that they decide upon, which may include permanent expulsion of the community member, the decision of the Cribl employees involved in a violation case will be considered final. We will respect confidentiality requests for the purpose of protecting victims of abuse. At our discretion, we may publicly name a person about whom we\u2019ve received harassment complaints, or privately warn third parties about them, if we believe that doing so will increase the safety of our members or the general public. We will not name harassment victims without their affirmative consent. Consequences Participants asked to stop any harassing behavior are expected to comply immediately. If a participant engages in harassing behavior, we may take any action they deem appropriate, up to and including permanent expulsion from the Cribl community and identification of the participant as a harasser to other members. At the discretion of the Cribl team or by request, one or more of the parties involved may request to discuss the violation and how to avoid similar situations in the future. Acknowledgements This Code of Conduct is adapted from the Community Covenant ( http://community-covenant.net ) version 1.0, available at http://community-covenant.net/version/1/0/ . The Community Covenant is an open source effort and is built on codes of conduct that came before it, including the Contributor Covenant (http://contributor-covenant.org/) and the LGBTQ in Tech community code of conduct ( http://lgbtq.technology/coc.html ). License Community Covenant by Coraline Ada Ehmke is licensed under a Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/). Based on a work at http://community-covenant.net/. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    },
    {
        "question_answer": {
            "question": "What is Cribl Search?",
            "answer": "Cribl Search is a tool that allows users to search data in place without having to collect or store it first.",
            "follow_up_question_1": "How does Cribl Search work?",
            "follow_up_answer_1": "Cribl Search works by leveraging the existing data infrastructure and indexing mechanisms. It allows users to search and analyze data in real-time, without the need to move or duplicate the data. This helps in reducing storage costs and improving query performance.",
            "follow_up_question_2": "What are the advantages of using Cribl Search?",
            "follow_up_answer_2": "Using Cribl Search provides a more efficient and cost-effective way of analyzing data. It eliminates the need for data duplication and reduces the time and effort required for data preparation. It also allows users to explore and analyze data in its original context, providing more accurate and meaningful insights.",
            "follow_up_question_3": "Can Cribl Search be integrated with other observability tools?",
            "follow_up_answer_3": "Yes, Cribl Search can be integrated with other observability tools and platforms. It provides APIs and connectors that allow seamless integration with existing systems, enabling users to leverage the power of Cribl Search alongside their existing tools and workflows.",
            "url": "https://cribl.io/cribl-community-code-of-conduct/"
        },
        "reference": "url,title,text_chunks https://cribl.io/cribl-community-code-of-conduct/,Cribl Community Code of Conduct - Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. This community is dedicated to providing a harassment-free experience for everyone. We do not tolerate harassment of participants in any form. All participants in the Cribl User Community are subject to these rules. These rules are enforced by Cribl employees/administrators, aka the Cribl team. (Cribl employees include the word \u201ccribl\u201d in their usernames so you can identify them.) Applicability and scope This code of conduct applies to all Cribl Community spaces and public channels, private channels, and direct messages, both online and off, as well as all Cribl-sponsored in-person events, including user group events and user conferences. When you register for any Cribl-sponsored event, you agree to comply with all rules and requirements provided by venues hosting Cribl-sponsored in-person events. Anyone who violates this code of conduct may be sanctioned or expelled from these spaces at the discretion of the Cribl team. Creating a welcoming and safe environment We hope to create an environment in which diverse individuals can collaborate and interact in a positive and affirming way. Examples of behavior that contributes to creating this sort of environment include: What we mean when we say \u201charassment\u201d The Cribl community will not tolerate harassment of any kind. Examples of harassment include: If you have questions or concerns about these rules, message a Cribl employee or email community@cribl.io. How to report an issue If you are being harassed by a member of our community, notice that someone else is being harassed, or have any other concerns, please notify a Cribl employee via Direct Message. Note: If the person who is harassing you is a Cribl employee, they will not be involved in handling or resolving the incident. The Cribl team will respond to any complaint as promptly as we can. If you do not get a timely response (for example, if no Cribl employees are currently online) then please put your personal safety and well-being first, and consider logging out and/or contacting us by email at community@cribl.io. This code of conduct applies to our community\u2019s spaces, but if you are being harassed by a member of our community outside our spaces, we still want to know about it. We will take all good-faith reports of harassment by our members seriously. This includes harassment outside our spaces and harassment that took place at any point in time. The Cribl team reserves the right to exclude people from the Cribl community based on their past behavior, including behavior outside of our spaces and behavior towards people who are not in this community. In order to protect admins from abuse and burnout, we reserve the right to reject any report we believe to have been made in bad faith. Reports intended to silence legitimate criticism may be deleted or ignored without response. How we will enforce these rules Every code of conduct violation report will be treated with seriousness and care. If a member\u2019s immediate safety and security is threatened, an individual Cribl employee may take any action that they deem appropriate, up to and including temporarily banning the offender from the Cribl community. In less immediate situations, at least two Cribl employees will discuss the offense and mutually arrive at a suitable response, which will be shared with the offender privately. Whatever the resolution that they decide upon, which may include permanent expulsion of the community member, the decision of the Cribl employees involved in a violation case will be considered final. We will respect confidentiality requests for the purpose of protecting victims of abuse. At our discretion, we may publicly name a person about whom we\u2019ve received harassment complaints, or privately warn third parties about them, if we believe that doing so will increase the safety of our members or the general public. We will not name harassment victims without their affirmative consent. Consequences Participants asked to stop any harassing behavior are expected to comply immediately. If a participant engages in harassing behavior, we may take any action they deem appropriate, up to and including permanent expulsion from the Cribl community and identification of the participant as a harasser to other members. At the discretion of the Cribl team or by request, one or more of the parties involved may request to discuss the violation and how to avoid similar situations in the future. Acknowledgements This Code of Conduct is adapted from the Community Covenant ( http://community-covenant.net ) version 1.0, available at http://community-covenant.net/version/1/0/ . The Community Covenant is an open source effort and is built on codes of conduct that came before it, including the Contributor Covenant (http://contributor-covenant.org/) and the LGBTQ in Tech community code of conduct ( http://lgbtq.technology/coc.html ). License Community Covenant by Coraline Ada Ehmke is licensed under a Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/). Based on a work at http://community-covenant.net/. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    },
    {
        "question_answer": {
            "question": "What is the purpose of the Curious + Community?",
            "answer": "The Curious + Community is a platform provided by Cribl for users to engage in general discussions.",
            "follow_up_question_1": "What kind of discussions can users have on the platform?",
            "follow_up_answer_1": "Users can have discussions on a wide range of topics, including technology, data management, and best practices.",
            "follow_up_question_2": "Are there any specific categories or topics within the community?",
            "follow_up_answer_2": "Yes, there are different categories within the community, such as general discussions, product feedback, and technical support.",
            "follow_up_question_3": "Can users ask questions and seek help on specific issues?",
            "follow_up_answer_3": "Absolutely! Users can ask questions and seek help from the community members who have expertise in various areas.",
            "follow_up_question_4": "Are there any guidelines or rules for participating in the community?",
            "follow_up_answer_4": "Yes, there are guidelines and a code of conduct that users are expected to follow to maintain a respectful and inclusive environment.",
            "follow_up_question_5": "How can users access the Curious + Community?",
            "follow_up_answer_5": "Users can access the community by visiting the Cribl website and navigating to the Curious + Community section.",
            "url": "https://community.cribl.io/categories/general-discussions"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/categories/general-discussions,General Discussions \u2014 Curious + Community,\u00a9 Cribl 2023 | Legal | Code of Conduct"
    },
    {
        "question_answer": {
            "question": "What is the importance of data management?",
            "answer": "Data management is crucial for organizations to effectively organize, store, and utilize their data.",
            "follow_up_question_1": "How does effective data management benefit organizations?",
            "follow_up_answer_1": "Effective data management allows organizations to make informed decisions, improve operational efficiency, and gain valuable insights from their data.",
            "follow_up_question_2": "What are some common challenges in data management?",
            "follow_up_answer_2": "Some common challenges in data management include data quality issues, data security concerns, and the need for efficient data integration.",
            "follow_up_question_3": "How can organizations ensure data quality?",
            "follow_up_answer_3": "Organizations can ensure data quality by implementing data validation processes, conducting regular data audits, and establishing data governance practices.",
            "follow_up_question_4": "What are some popular data management tools?",
            "follow_up_answer_4": "Some popular data management tools include data integration platforms, data governance solutions, and data quality management software.",
            "follow_up_question_5": "Are there any best practices for data management?",
            "follow_up_answer_5": "Yes, some best practices for data management include establishing clear data policies, implementing data backup and recovery strategies, and regularly monitoring data quality.",
            "url": "https://community.cribl.io/categories/general-discussions"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/categories/general-discussions,General Discussions \u2014 Curious + Community,\u00a9 Cribl 2023 | Legal | Code of Conduct"
    },
    {
        "question_answer": {
            "question": "How does Cribl help with data management?",
            "answer": "Cribl provides solutions that help organizations streamline their data management processes.",
            "follow_up_question_1": "What are some key features of Cribl's data management solutions?",
            "follow_up_answer_1": "Cribl's data management solutions offer features such as data routing, transformation, and enrichment, as well as real-time data processing capabilities.",
            "follow_up_question_2": "How can Cribl's solutions improve data management efficiency?",
            "follow_up_answer_2": "Cribl's solutions can improve data management efficiency by reducing data silos, optimizing data pipelines, and enabling organizations to extract more value from their data.",
            "follow_up_question_3": "Can Cribl's solutions integrate with existing data infrastructure?",
            "follow_up_answer_3": "Yes, Cribl's solutions are designed to seamlessly integrate with existing data infrastructure, including various data sources, storage systems, and analytics platforms.",
            "follow_up_question_4": "Are there any case studies or success stories of organizations using Cribl's solutions?",
            "follow_up_answer_4": "Yes, Cribl has several case studies and success stories showcasing how organizations have benefited from implementing their data management solutions.",
            "follow_up_question_5": "How can organizations get started with Cribl's data management solutions?",
            "follow_up_answer_5": "Organizations can get started by contacting Cribl's sales team or visiting their website to learn more about their solutions and request a demo.",
            "url": "https://community.cribl.io/categories/general-discussions"
        },
        "reference": "url,title,text_chunks https://community.cribl.io/categories/general-discussions,General Discussions \u2014 Curious + Community,\u00a9 Cribl 2023 | Legal | Code of Conduct"
    },
    {
        "question_answer": {
            "question": "What is observability?",
            "answer": "Observability is the ability to understand and analyze the internal state and behavior of a system based on its external outputs. It involves collecting and analyzing data from various sources, such as logs, metrics, and traces, to gain insights into the performance, availability, and reliability of the system.",
            "follow_up_question_1": "How can observability help improve system performance?",
            "follow_up_answer_1": "Observability provides visibility into the inner workings of a system, allowing engineers to identify and diagnose issues that may be impacting performance. By analyzing data from different sources, engineers can pinpoint bottlenecks, optimize resource allocation, and make informed decisions to improve overall system performance.",
            "follow_up_question_2": "Are there any specific tools or technologies used for observability?",
            "follow_up_answer_2": "Yes, there are various tools and technologies available for observability. Some popular ones include logging platforms like Elasticsearch and Splunk, monitoring systems like Prometheus and Grafana, and distributed tracing systems like Jaeger and Zipkin. These tools help collect, store, and analyze data from different sources to provide comprehensive observability.",
            "follow_up_question_3": "How can observability benefit businesses?",
            "follow_up_answer_3": "Observability can benefit businesses in several ways. It helps improve system reliability and availability, leading to better customer experiences. It also enables proactive monitoring and troubleshooting, reducing downtime and minimizing the impact of issues. Additionally, observability provides valuable insights for capacity planning, resource optimization, and identifying opportunities for business growth and innovation.",
            "url": "https://cribl.io/community/cribl-community-group/"
        },
        "reference": "url,title,text_chunks https://cribl.io/community/cribl-community-group/,Connecting with Monthly Community User Group Meetings | Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    },
    {
        "question_answer": {
            "question": "What is Cribl Stream?",
            "answer": "Cribl Stream is a vendor-agnostic observability pipeline that allows you to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure.",
            "follow_up_question_1": "How does Cribl Stream handle data collection?",
            "follow_up_answer_1": "Cribl Stream provides a highly scalable and intelligent data collection system for logs, metrics, and application data. It can collect data from various sources, including cloud platforms, on-premises systems, and third-party tools, and normalize it for further processing and analysis.",
            "follow_up_question_2": "Can Cribl Stream integrate with existing data infrastructure?",
            "follow_up_answer_2": "Yes, Cribl Stream is designed to seamlessly integrate with your existing data infrastructure. It supports a wide range of data destinations, such as data lakes, analytics platforms, SIEMs, and more. It also provides flexible routing capabilities, allowing you to send data to specific destinations based on predefined rules and conditions.",
            "follow_up_question_3": "What are the benefits of using Cribl Stream?",
            "follow_up_answer_3": "Using Cribl Stream can help improve data quality, reduce storage costs, and enhance data processing efficiency. It allows you to filter and enrich data in real-time, ensuring that only relevant and valuable data is stored and analyzed. Additionally, Cribl Stream provides a centralized platform for managing data pipelines, making it easier to monitor and troubleshoot data flows.",
            "url": "https://cribl.io/community/cribl-community-group/"
        },
        "reference": "url,title,text_chunks https://cribl.io/community/cribl-community-group/,Connecting with Monthly Community User Group Meetings | Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    },
    {
        "question_answer": {
            "question": "What is Cribl Search?",
            "answer": "Cribl Search is a tool that turns the traditional search process on its head by allowing users to search data in place without having to collect or store it first.",
            "follow_up_question_1": "How does Cribl Search work?",
            "follow_up_answer_1": "Cribl Search leverages the power of distributed search engines, such as Elasticsearch, to enable fast and efficient searching of data in its original location. It uses indexing and query optimization techniques to provide real-time search capabilities without the need for data duplication or storage.",
            "follow_up_question_2": "What are the advantages of using Cribl Search?",
            "follow_up_answer_2": "Using Cribl Search eliminates the need for data duplication and storage, reducing storage costs and complexity. It also enables faster and more efficient search operations, as data can be searched in its original location without the need for data movement. Additionally, Cribl Search provides a user-friendly interface and powerful query capabilities, making it easier to explore and analyze data.",
            "follow_up_question_3": "Can Cribl Search be integrated with other observability tools?",
            "follow_up_answer_3": "Yes, Cribl Search can be integrated with other observability tools, such as logging platforms and monitoring systems. It can act as a search layer on top of existing data sources, allowing users to search and analyze data from multiple sources in a unified manner. This integration enhances the overall observability capabilities and provides a seamless user experience.",
            "url": "https://cribl.io/community/cribl-community-group/"
        },
        "reference": "url,title,text_chunks https://cribl.io/community/cribl-community-group/,Connecting with Monthly Community User Group Meetings | Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    },
    {
        "question_answer": {
            "question": "What is AppScope?",
            "answer": "AppScope is a Cribl solution that provides operators with visibility into application behavior, metrics, and events without the need for any configuration or agent installation.",
            "follow_up_question_1": "How does AppScope work?",
            "follow_up_answer_1": "AppScope leverages the power of eBPF (extended Berkeley Packet Filter) technology to capture and analyze network traffic at the kernel level. It automatically detects and profiles applications, allowing operators to gain insights into application performance, dependencies, and security without any manual configuration or code changes.",
            "follow_up_question_2": "What are the benefits of using AppScope?",
            "follow_up_answer_2": "Using AppScope eliminates the need for manual configuration and agent installation, reducing the operational overhead and complexity. It provides real-time visibility into application behavior, allowing operators to identify performance bottlenecks, troubleshoot issues, and ensure compliance with security policies. Additionally, AppScope integrates seamlessly with other Cribl solutions, enabling a comprehensive observability ecosystem.",
            "follow_up_question_3": "Can AppScope be used in any type of application environment?",
            "follow_up_answer_3": "Yes, AppScope is designed to work in any type of application environment, including cloud-native, hybrid, and on-premises environments. It supports a wide range of operating systems and container platforms, making it suitable for diverse application architectures. Whether you're running microservices, monolithic applications, or containerized workloads, AppScope can provide valuable insights into your application ecosystem.",
            "url": "https://cribl.io/community/cribl-community-group/"
        },
        "reference": "url,title,text_chunks https://cribl.io/community/cribl-community-group/,Connecting with Monthly Community User Group Meetings | Cribl,\"New to observability? Find out everything you need to know. Telemetry 101 Understanding the Basics of Telemetry and Its Benefits Cribl Stream is a vendor-agnostic observability pipeline that gives you the flexibility to collect, reduce, enrich, normalize, and route data from any source to any destination within your existing data infrastructure. Vodafone Case Study Vodafone Dials up Business Insights with Cribl Stream Cribl Edge provides an intelligent, highly scalable edge-based data collection system for logs, metrics, and application data. SpyCloud Edge Story Listen to how SpyCloud uses Cribl Edge at scale. Cribl Search turns the traditional search process on its head, allowing users to search data in place without having to collect/store first. Happy 1st Birthday Cribl Search! The Cribl.Cloud platform gets you up and running fast without the hassle of running infrastructure. Cribl.Cloud Solution Brief The fastest and easiest way to realize the value of an observability ecosystem. AppScope gives operators the visibility they need into application behavior, metrics and events with no configuration and no agent required. Sandbox Launch an AppScope Sandbox today! Explore Cribl\u2019s Solutions by Use Cases: Explore Cribl\u2019s Solutions by Integrations: Seamless Integrations for Your Observability Data Explore Cribl\u2019s Solutions by Industry: Get this Gartner\u00ae report and learn why telemetry pipeline solutions represent a robust and largely untapped source of business insight beyond event and incident response. CriblCon 2023 Escaping Data Lock-In Amidst Industry Takeovers Learn how IT & Security engineers increase resilience & provide more options for analysis to make decisions faster with better data. Try Your Own Cribl Sandbox Experience a full version of Cribl Stream and Cribl Edge in the cloud. Download Cribl\u2019s suite of products for free to get started. Get inspired by how our customers are innovating IT, security and observability. They inspire us daily! Sally Beauty Holdings Sally Beauty Swaps LogStash and Syslog-ng with Cribl.Cloud for a Resilient Security and Observability Pipeline Professional Services Check out our new Professional Services offering. Experience a full version of Cribl Stream and Cribl Edge in the cloud. Take Control of Your Observability Data with Cribl Cribl Corporate Overview Cribl makes open observability a reality, giving you the freedom and flexibility to make choices instead of compromises. Stay up to date on all things Cribl and observability. Press Releases Read our most recent press releases. Cribl\u2019s leadership team has built and launched category-defining products for some of the most innovative companies in the technology sector, and is supported by the world\u2019s most elite investors. Join the Cribl herd! The smartest, funniest, most passionate goats you\u2019ll ever meet. Cribl Named to the Inc. 5000 List of Fastest Growing Private Companies Want to learn more about Cribl from our sales experts? Send us your contact information and we\u2019ll be in touch. \u00a92018 \u2013 2023 Cribl, Inc. | Legal\""
    }
]