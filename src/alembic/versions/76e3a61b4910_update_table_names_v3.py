"""update table names v3

Revision ID: 76e3a61b4910
Revises: 
Create Date: 2024-01-20 14:46:29.507803

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '76e3a61b4910'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('api_tokens',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('userid', sa.String(), nullable=True),
    sa.Column('orgid', sa.String(), nullable=True),
    sa.Column('name', sa.String(), nullable=True),
    sa.Column('token', sa.String(), nullable=True),
    sa.Column('ts', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_api_tokens_id'), 'api_tokens', ['id'], unique=False)
    op.create_table('datasets',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('gen_id', sa.String(), nullable=True),
    sa.Column('name', sa.String(), nullable=True),
    sa.Column('userid', sa.String(), nullable=True),
    sa.Column('orgid', sa.String(), nullable=True),
    sa.Column('type', sa.String(), nullable=True),
    sa.Column('chat_type', sa.String(), nullable=True),
    sa.Column('sample_size', sa.Integer(), nullable=True),
    sa.Column('number_of_questions', sa.Integer(), nullable=True),
    sa.Column('chunk_size', sa.Integer(), nullable=True),
    sa.Column('reference_chunk_max_distance', sa.Integer(), nullable=True),
    sa.Column('ts', sa.DateTime(), nullable=True),
    sa.Column('dataset_type', sa.String(), nullable=True),
    sa.Column('model_name', sa.String(), nullable=True),
    sa.Column('persona', sa.String(), nullable=True),
    sa.Column('behavior', sa.String(), nullable=True),
    sa.Column('demographic', sa.String(), nullable=True),
    sa.Column('sentiment', sa.String(), nullable=True),
    sa.Column('error_type', sa.String(), nullable=True),
    sa.Column('follow_up_depth', sa.Integer(), nullable=True),
    sa.Column('resident_type', sa.String(), nullable=True),
    sa.Column('family_status', sa.String(), nullable=True),
    sa.Column('qa_type', sa.String(), nullable=True),
    sa.Column('crawl_depth', sa.Integer(), nullable=True),
    sa.Column('max_crawl_links', sa.Integer(), nullable=True),
    sa.Column('status', sa.String(), nullable=True),
    sa.Column('error_msg', sa.String(), nullable=True),
    sa.Column('data_source', sa.String(), nullable=True),
    sa.Column('tags', sa.String(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_datasets_gen_id'), 'datasets', ['gen_id'], unique=False)
    op.create_index(op.f('ix_datasets_id'), 'datasets', ['id'], unique=False)
    op.create_index(op.f('ix_datasets_name'), 'datasets', ['name'], unique=False)
    op.create_table('llm_endpoints',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('userid', sa.String(), nullable=True),
    sa.Column('orgid', sa.String(), nullable=True),
    sa.Column('name', sa.String(), nullable=True),
    sa.Column('endpoint_url', sa.String(), nullable=True),
    sa.Column('ts', sa.DateTime(), nullable=True),
    sa.Column('access_token', sa.String(), nullable=True),
    sa.Column('payload_format', sa.String(), nullable=True),
    sa.Column('payload_user_key', sa.String(), nullable=True),
    sa.Column('payload_message_key', sa.String(), nullable=True),
    sa.Column('payload_response_key', sa.String(), nullable=True),
    sa.Column('http_method', sa.String(), nullable=True),
    sa.Column('requests_per_minute', sa.Integer(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_llm_endpoints_id'), 'llm_endpoints', ['id'], unique=False)
    op.create_index(op.f('ix_llm_endpoints_name'), 'llm_endpoints', ['name'], unique=False)
    op.create_table('evaluation_profiles',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(), nullable=True),
    sa.Column('userid', sa.String(), nullable=True),
    sa.Column('orgid', sa.String(), nullable=True),
    sa.Column('endpoint_url_id', sa.Integer(), nullable=True),
    sa.Column('dataset_id', sa.Integer(), nullable=True),
    sa.Column('num_users', sa.Integer(), nullable=True),
    sa.Column('percentage_of_questions', sa.Integer(), nullable=True),
    sa.Column('order_of_questions', sa.String(), nullable=True),
    sa.Column('ts', sa.DateTime(), nullable=True),
    sa.Column('simulation_id', sa.String(), nullable=True),
    sa.Column('status', sa.String(), nullable=True),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ),
    sa.ForeignKeyConstraint(['endpoint_url_id'], ['llm_endpoints.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_evaluation_profiles_id'), 'evaluation_profiles', ['id'], unique=False)
    op.create_table('qa_data',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('userid', sa.String(), nullable=True),
    sa.Column('orgid', sa.String(), nullable=True),
    sa.Column('dataset_id', sa.Integer(), nullable=True),
    sa.Column('ts', sa.DateTime(), nullable=True),
    sa.Column('chat_messages', sa.JSON(), nullable=True),
    sa.Column('reference_chunk', sa.String(), nullable=True),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_qa_data_id'), 'qa_data', ['id'], unique=False)
    op.create_table('evaluation_runs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('orgid', sa.String(), nullable=True),
    sa.Column('simulation_id', sa.Integer(), nullable=True),
    sa.Column('ts', sa.DateTime(), nullable=True),
    sa.Column('score', sa.Float(), nullable=True),
    sa.Column('run_status', sa.String(), nullable=True),
    sa.Column('evaluation_id', sa.String(), nullable=True),
    sa.ForeignKeyConstraint(['simulation_id'], ['evaluation_profiles.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_evaluation_runs_id'), 'evaluation_runs', ['id'], unique=False)
    op.create_table('assessments',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('simulation_userid', sa.String(), nullable=True),
    sa.Column('orgid', sa.String(), nullable=True),
    sa.Column('dataset_id', sa.Integer(), nullable=True),
    sa.Column('llm_endpoint_id', sa.Integer(), nullable=True),
    sa.Column('qa_data_id', sa.Integer(), nullable=True),
    sa.Column('simulation_id', sa.Integer(), nullable=True),
    sa.Column('simulation_run_id', sa.Integer(), nullable=True),
    sa.Column('ts', sa.DateTime(), nullable=True),
    sa.Column('score', sa.Float(), nullable=True),
    sa.Column('score_reason', sa.String(), nullable=True),
    sa.Column('endpoint_response', sa.String(), nullable=True),
    sa.Column('evaluation_id', sa.String(), nullable=True),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ),
    sa.ForeignKeyConstraint(['llm_endpoint_id'], ['llm_endpoints.id'], ),
    sa.ForeignKeyConstraint(['qa_data_id'], ['qa_data.id'], ),
    sa.ForeignKeyConstraint(['simulation_id'], ['evaluation_profiles.id'], ),
    sa.ForeignKeyConstraint(['simulation_run_id'], ['evaluation_runs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_assessments_id'), 'assessments', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_assessments_id'), table_name='assessments')
    op.drop_table('assessments')
    op.drop_index(op.f('ix_evaluation_runs_id'), table_name='evaluation_runs')
    op.drop_table('evaluation_runs')
    op.drop_index(op.f('ix_qa_data_id'), table_name='qa_data')
    op.drop_table('qa_data')
    op.drop_index(op.f('ix_evaluation_profiles_id'), table_name='evaluation_profiles')
    op.drop_table('evaluation_profiles')
    op.drop_index(op.f('ix_llm_endpoints_name'), table_name='llm_endpoints')
    op.drop_index(op.f('ix_llm_endpoints_id'), table_name='llm_endpoints')
    op.drop_table('llm_endpoints')
    op.drop_index(op.f('ix_datasets_name'), table_name='datasets')
    op.drop_index(op.f('ix_datasets_id'), table_name='datasets')
    op.drop_index(op.f('ix_datasets_gen_id'), table_name='datasets')
    op.drop_table('datasets')
    op.drop_index(op.f('ix_api_tokens_id'), table_name='api_tokens')
    op.drop_table('api_tokens')
    # ### end Alembic commands ###
